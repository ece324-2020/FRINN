{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4187IAb6xjUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f833bc9b-a9a7-49f2-c50b-2e9eba416d3e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import numpy as np                                                                                          \n",
        "import matplotlib.pyplot as plt                                 \n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder   \n",
        "import torchvision                \n",
        "import torchvision.transforms as transforms      \n",
        "from torch.utils.data import DataLoader          \n",
        "from torch.utils.data import SubsetRandomSampler \n",
        "import torch.utils.data as data   \n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/ECE324 project/Additional files')\n",
        "sys.path.append('/content/gdrive/My Drive/ECE324 project/data')\n",
        "\n",
        "from Data_Loader import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "wImwLloDYkyJ",
        "outputId": "33cd278f-bba0-4575-e7cc-7e36606d0e59"
      },
      "source": [
        "'''\n",
        "my_transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.ToPILImage(),\n",
        "  transforms.Resize((224,224)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean = [0.66445047,0.55465436,0.447036], std = [0.321551,0.33547384,0.3524585])\n",
        "  ])\n",
        "\n",
        "dataset =  torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/ECE324 project/data_overfit', transform=my_transform)\n",
        "\n",
        "\n",
        "#train_loader = DataLoader(dataset, batch_size=45,shuffle= True)\n",
        "dataset.classes'''\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nmy_transform = transforms.Compose([\\n  transforms.ToTensor(),\\n  transforms.ToPILImage(),\\n  transforms.Resize((224,224)),\\n  transforms.ToTensor(),\\n  transforms.Normalize(mean = [0.66445047,0.55465436,0.447036], std = [0.321551,0.33547384,0.3524585])\\n  ])\\n\\ndataset =  torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/ECE324 project/data_overfit', transform=my_transform)\\n\\n\\n#train_loader = DataLoader(dataset, batch_size=45,shuffle= True)\\ndataset.classes\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBMEl5FyiFju",
        "outputId": "4f52fa56-5ce8-4eff-df50-685ceaec6be4"
      },
      "source": [
        "my_transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.ToPILImage(),\n",
        "  transforms.Resize((224,224)),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize(mean = [0.66445047,0.55465436,0.447036], std = [0.321551,0.33547384,0.3524585])\n",
        "  ])\n",
        "\n",
        "dataset_clean =  torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/ECE324 project/Clean Data', transform=my_transform)\n",
        "\n",
        "print(len(dataset_clean)) # 14999\n",
        "train_data, valid_data, test_data = torch.utils.data.random_split(dataset_clean, [9600,2400,2999], generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)                  \n",
        "valid_loader = DataLoader(valid_data, batch_size=64)\n",
        "test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "test_white =  torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/ECE324 project/test_white_bg', transform=my_transform)\n",
        "test_varied =  torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/ECE324 project/test_varied_bg', transform=my_transform)\n",
        "\n",
        "test_white_loader = DataLoader(test_white, batch_size=8)\n",
        "test_varied_loader = DataLoader(test_varied, batch_size=8)\n",
        "print(len(test_white))\n",
        "print(len(test_varied))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14999\n",
            "75\n",
            "75\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZwugdy_-dy4",
        "outputId": "de038a87-1891-4df6-8d60-322113c57fe9"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "Tue Nov 24 02:22:34 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    26W / 300W |     10MiB / 16130MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkSWS9Lh0HXh"
      },
      "source": [
        "from torchvision import models\n",
        "from torch import nn\n",
        "vgg = models.vgg16_bn(pretrained=True)\n",
        "for param in vgg.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "#vgg.features[43] = nn.Sequential(vgg.features[43],nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
        "#                nn.ReLU(inplace=True))\n",
        "\n",
        "#vgg.features[43] = nn.Sequential(vgg.features[43],nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
        "#                nn.ReLU(inplace=True),nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),nn.Dropout(p=0.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1JJW3IZ9r46"
      },
      "source": [
        "class MyVgg(nn.Module):\n",
        "    def __init__(self,originalmodel):\n",
        "        super(MyVgg,self).__init__()\n",
        "        vgg = originalmodel\n",
        "        # Here you get the bottleneck/feature extractor\n",
        "        self.vgg_feature_extractor = nn.Sequential(*list(vgg.children())[:-1])\n",
        "\n",
        "        self.classifier1 = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(4096, 3),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.classifier2 = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Linear(4096, 5),\n",
        "            nn.Sigmoid()\n",
        "                            )\n",
        "\n",
        "    # Set your own forward pass\n",
        "    def forward(self, img, extra_info=None):\n",
        "\n",
        "        x = self.vgg_feature_extractor(img)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x1 = self.classifier1(x)\n",
        "        x2 = self.classifier2(x)\n",
        "\n",
        "        return x1, x2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAGuF9aaFrXm"
      },
      "source": [
        "#MODEL ARGUMENTS\n",
        "lr = 0.03\n",
        "epochs = 20\n",
        "eval_every = 5\n",
        "model = MyVgg(vgg)\n",
        "model.to(device)\n",
        "my_optim = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "decayRate = 0.96\n",
        "my_lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=my_optim, gamma=decayRate)\n",
        "loss_fnc= torch.nn.CrossEntropyLoss() \n",
        "loss_fnc.to(device)\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "\n",
        "#OUTPUT DATA ARGUMENTS\n",
        "seed = 1\n",
        "torch.manual_seed(seed)\n",
        "save= True\n",
        "confusion=True\n",
        "plot = True\n",
        "statistics = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5knyG611Y2bS"
      },
      "source": [
        "def relabel_state(argument):\n",
        "    switcher = {\n",
        "        0: 0,\n",
        "        1: 0,\n",
        "        2: 0,\n",
        "        3: 0,\n",
        "        4: 0,\n",
        "        5: 1,\n",
        "        6: 1,\n",
        "        7: 1,\n",
        "        8: 1,\n",
        "        9: 1,\n",
        "        10:2,\n",
        "        11:2,\n",
        "        12:2,\n",
        "        13:2,\n",
        "        14:2}\n",
        "    return switcher[argument.item()]\n",
        "\n",
        "def relabel_type(argument):\n",
        "    switcher = {\n",
        "        0: 0,\n",
        "        1: 1,\n",
        "        2: 2,\n",
        "        3: 3,\n",
        "        4: 4,\n",
        "        5: 0,\n",
        "        6: 1,\n",
        "        7: 2,\n",
        "        8: 3,\n",
        "        9: 4,\n",
        "        10:0,\n",
        "        11:1,\n",
        "        12:2,\n",
        "        13:3,\n",
        "        14:4}\n",
        "    return switcher[argument.item()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2v81BweaVRd"
      },
      "source": [
        "class StopExecution(Exception):\n",
        "    def _render_traceback_(self):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWOdp7axHnhB"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=1, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "            path (str): Path for the checkpoint to be saved to.\n",
        "                            Default: 'checkpoint.pt'\n",
        "            trace_func (function): trace print function.\n",
        "                            Default: print            \n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.trace_func = trace_func\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgwB8Rg7Y25Z",
        "outputId": "bc323e21-86ba-47da-e1c8-3ba1bf06c516"
      },
      "source": [
        "train_loss_list = []\n",
        "train_acc_list = []\n",
        "train_loss_list_state = []\n",
        "train_acc_list_state = []\n",
        "train_loss_list_type = []\n",
        "train_acc_list_type = []\n",
        "\n",
        "valid_loss_list = []\n",
        "valid_acc_list = []\n",
        "valid_loss_list_state = []\n",
        "valid_acc_list_state = []\n",
        "valid_loss_list_type = []\n",
        "valid_acc_list_type = []\n",
        "\n",
        "epoch_list = []         #Epoch number\n",
        "start = time()\n",
        "\n",
        "for e in range(epochs):\n",
        "    model.train()\n",
        "    print(\"Time:    \", time() - start)\n",
        "    running_loss = []\n",
        "    running_accuracy = []\n",
        "    running_loss_state = []\n",
        "    running_accuracy_state = []\n",
        "    running_loss_type = []\n",
        "    running_accuracy_type = []\n",
        "\n",
        "    running_valid_loss = []\n",
        "    running_valid_accuracy = []\n",
        "    running_valid_loss_state = []\n",
        "    running_valid_accuracy_state = []\n",
        "    running_valid_loss_type = []\n",
        "    running_valid_accuracy_type = []\n",
        "\n",
        "  #               LOOKING AT TRAINING DATA\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "\n",
        "            #get batch of data\n",
        "        inputs, label = data[0].to(device), data[1].to(device)\n",
        "    \n",
        "        label_state = torch.zeros(len(label)).to(device)\n",
        "        label_type = torch.zeros(len(label)).to(device)\n",
        "\n",
        "        for k in range(len(label)):\n",
        "          label_state[k] = relabel_state(label[k])\n",
        "          label_type[k] = relabel_type(label[k])\n",
        "\n",
        "        \n",
        "        # Setting gradients to zero and running model on batch\n",
        "        my_optim.zero_grad()\n",
        "        predictions_state, predictions_type = model(inputs)\n",
        "\n",
        "        # Computing loss based on Cross Entropy\n",
        "        batch_loss_state = loss_fnc(input=predictions_state.squeeze(), target=label_state.long())\n",
        "        batch_loss_type = loss_fnc(input=predictions_type.squeeze(), target=label_type.long())\n",
        "\n",
        "        # Combining losses and calculating gradients\n",
        "        Overall_loss = batch_loss_state + batch_loss_type\n",
        "        Overall_loss.backward()\n",
        "        my_optim.step()\n",
        "        # Evaluating Training Acc\n",
        "        _, predicted_state = torch.max(predictions_state.data, 1)\n",
        "        _,predicted_type = torch.max(predictions_type.data, 1)\n",
        "\n",
        "        trainAcc_state = (label_state == predicted_state).sum().item() / 64\n",
        "        trainAcc_type = (label_type == predicted_type).sum().item() / 64\n",
        "\n",
        "        if i % eval_every == 0:\n",
        "           print(\"epoch: {} {} |||   loss type:   {}  trainAcc type:   {} |||  loss state {}  trainAcc state:  {}  \".format(e+1,i, batch_loss_type, trainAcc_type, batch_loss_state, trainAcc_state))\n",
        "\n",
        "        running_loss.append(Overall_loss.item())\n",
        "        running_accuracy.append((trainAcc_state+trainAcc_type)/2)\n",
        "        running_loss_state.append(batch_loss_state.item())\n",
        "        running_accuracy_state.append(trainAcc_state)\n",
        "        running_loss_type.append(batch_loss_type.item())\n",
        "        running_accuracy_type.append(trainAcc_type)\n",
        "\n",
        "        del Overall_loss\n",
        "        del batch_loss_state\n",
        "        del batch_loss_type\n",
        "        del label_state\n",
        "        del label_type\n",
        "        del predictions_state\n",
        "        del predictions_type\n",
        "  \n",
        "    for j, data in enumerate(valid_loader):\n",
        "        model.eval()\n",
        "            #get batch of data\n",
        "        inputs, label = data[0].to(device), data[1].to(device)\n",
        "    \n",
        "        vlabel_state = torch.zeros(len(label)).to(device)\n",
        "        vlabel_type = torch.zeros(len(label)).to(device)\n",
        "\n",
        "        for k in range(len(label)):\n",
        "          vlabel_state[k] = relabel_state(label[k])\n",
        "          vlabel_type[k] = relabel_type(label[k]) \n",
        "\n",
        "          #run model on validation batch\n",
        "        predictions_state_v, predictions_type_v = model(inputs)\n",
        "\n",
        "            #compute loss\n",
        "        batch_valid_loss_state = loss_fnc(input=predictions_state_v.squeeze(), target=vlabel_state.long())\n",
        "        batch_valid_loss_type = loss_fnc(input=predictions_type_v.squeeze(), target=vlabel_type.long())\n",
        "\n",
        "        Overall_loss_v = batch_valid_loss_state.float() + batch_valid_loss_type.float()\n",
        "\n",
        "            #evaluate\n",
        "        _, predicted_state_v = torch.max(predictions_state_v.data, 1)\n",
        "        _,predicted_type_v = torch.max(predictions_type_v.data, 1)\n",
        "\n",
        "        validAcc_state = (vlabel_state == predicted_state_v).sum().item() / 64\n",
        "        validAcc_type = (vlabel_type == predicted_type_v).sum().item() / 64\n",
        "\n",
        "        if j % eval_every == 0:\n",
        "             print(\"epoch: {} |||   vloss type:   {}  validAcc type:   {} |||  vloss state {}  validAcc state:  {}  \".format(e+1, batch_valid_loss_type, validAcc_type, batch_valid_loss_state,validAcc_state))\n",
        "        \n",
        "        running_valid_loss.append(Overall_loss_v.item())\n",
        "        running_valid_accuracy.append((validAcc_state+validAcc_type)/2)\n",
        "        running_valid_loss_state.append(batch_valid_loss_state.item())\n",
        "        running_valid_accuracy_state.append(validAcc_state)\n",
        "        running_valid_loss_type.append(batch_valid_loss_type.item())\n",
        "        running_valid_accuracy_type.append(validAcc_type) \n",
        "\n",
        "        del Overall_loss_v\n",
        "        del batch_valid_loss_state\n",
        "        del batch_valid_loss_type\n",
        "        del vlabel_state\n",
        "        del vlabel_type\n",
        "        del predictions_state_v\n",
        "        del predictions_type_v\n",
        "\n",
        "    #Overall accuracy\n",
        "    trainacc_ = sum(running_accuracy) / float(len(running_accuracy))\n",
        "    train_acc_list.append(trainacc_)\n",
        "    #state accuracy\n",
        "    trainacc_state_ = sum(running_accuracy_state) / float(len(running_accuracy_state))\n",
        "    train_acc_list_state.append(trainacc_state_)\n",
        "    #type accuracy\n",
        "    trainAcc_type_ = sum(running_accuracy_type) / float(len(running_accuracy_type))\n",
        "    train_acc_list_type.append(trainAcc_type_) \n",
        "\n",
        "    #             lists for TRAINING losses\n",
        "    #Overall Loss\n",
        "    loss_ = sum(running_loss) / float(len(running_loss))\n",
        "    train_loss_list.append(loss_)\n",
        "    #State Loss\n",
        "    loss_state_ = sum(running_loss_state) / float(len(running_loss_state))\n",
        "    train_loss_list_state.append(loss_state_)\n",
        "    #Type Loss\n",
        "    loss_type_ = sum(running_loss_type) / float(len(running_loss_type))\n",
        "    train_loss_list_type.append(loss_type_) \n",
        "\n",
        "    #------------------------------------------------------------------------------------\n",
        "    #             lists for VALIDATION accuracy\n",
        "    #Overall accuracy\n",
        "    validacc_ = sum(running_valid_accuracy) / float(len(running_valid_accuracy))\n",
        "    valid_acc_list.append(validacc_)\n",
        "    #state accuracy\n",
        "    validacc_state_ = sum(running_valid_accuracy_state) / float(len(running_valid_accuracy_state))\n",
        "    valid_acc_list_state.append(validacc_state_)\n",
        "    #type accuracy\n",
        "    validAcc_type_ = sum(running_valid_accuracy_type) / float(len(running_valid_accuracy_type))\n",
        "    valid_acc_list_type.append(validAcc_type_)\n",
        "\n",
        "    #             lists for VALIDATION losses\n",
        "    #Overall Loss\n",
        "    valid_loss_ = sum(running_valid_loss) / float(len(running_valid_loss))\n",
        "    valid_loss_list.append(valid_loss_)\n",
        "    #State Loss\n",
        "    valid_loss_state_ = sum(running_valid_loss_state) / float(len(running_valid_loss_state))\n",
        "    valid_loss_list_state.append(valid_loss_state_)\n",
        "    #Type Loss\n",
        "    valid_loss_type_ = sum(running_valid_loss_type) / float(len(running_valid_loss_type))\n",
        "    valid_loss_list_type.append(valid_loss_type_)\n",
        "\n",
        "    a=EarlyStopping(valid_loss_, model)\n",
        "\n",
        "    if a.early_stop == True:\n",
        "        print(\"Early stopping\")\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:     0.0010533332824707031\n",
            "epoch: 1 0 |||   loss type:   1.6074334383010864  trainAcc type:   0.265625 |||  loss state 1.0987586975097656  trainAcc state:  0.3125  \n",
            "epoch: 1 5 |||   loss type:   1.5640426874160767  trainAcc type:   0.625 |||  loss state 1.0768061876296997  trainAcc state:  0.625  \n",
            "epoch: 1 10 |||   loss type:   1.5648763179779053  trainAcc type:   0.4375 |||  loss state 1.0674899816513062  trainAcc state:  0.75  \n",
            "epoch: 1 15 |||   loss type:   1.5416715145111084  trainAcc type:   0.625 |||  loss state 1.0476917028427124  trainAcc state:  0.796875  \n",
            "epoch: 1 20 |||   loss type:   1.4996317625045776  trainAcc type:   0.84375 |||  loss state 1.017125129699707  trainAcc state:  0.765625  \n",
            "epoch: 1 25 |||   loss type:   1.4263581037521362  trainAcc type:   0.921875 |||  loss state 0.9958961606025696  trainAcc state:  0.828125  \n",
            "epoch: 1 30 |||   loss type:   1.4632457494735718  trainAcc type:   0.796875 |||  loss state 0.9920494556427002  trainAcc state:  0.796875  \n",
            "epoch: 1 35 |||   loss type:   1.4207682609558105  trainAcc type:   0.859375 |||  loss state 0.9712602496147156  trainAcc state:  0.828125  \n",
            "epoch: 1 40 |||   loss type:   1.3197407722473145  trainAcc type:   0.921875 |||  loss state 0.946650505065918  trainAcc state:  0.8125  \n",
            "epoch: 1 45 |||   loss type:   1.3566539287567139  trainAcc type:   0.953125 |||  loss state 0.9376000165939331  trainAcc state:  0.859375  \n",
            "epoch: 1 50 |||   loss type:   1.3037052154541016  trainAcc type:   0.875 |||  loss state 0.8950364589691162  trainAcc state:  0.828125  \n",
            "epoch: 1 55 |||   loss type:   1.323901891708374  trainAcc type:   0.921875 |||  loss state 0.8882248401641846  trainAcc state:  0.96875  \n",
            "epoch: 1 60 |||   loss type:   1.299232006072998  trainAcc type:   0.890625 |||  loss state 0.8763699531555176  trainAcc state:  0.921875  \n",
            "epoch: 1 65 |||   loss type:   1.284243106842041  trainAcc type:   0.90625 |||  loss state 0.8509146571159363  trainAcc state:  0.890625  \n",
            "epoch: 1 70 |||   loss type:   1.2018494606018066  trainAcc type:   0.9375 |||  loss state 0.805676281452179  trainAcc state:  0.890625  \n",
            "epoch: 1 75 |||   loss type:   1.184988021850586  trainAcc type:   0.953125 |||  loss state 0.8029442429542542  trainAcc state:  0.875  \n",
            "epoch: 1 80 |||   loss type:   1.2196837663650513  trainAcc type:   0.953125 |||  loss state 0.8620872497558594  trainAcc state:  0.78125  \n",
            "epoch: 1 85 |||   loss type:   1.1621671915054321  trainAcc type:   0.9375 |||  loss state 0.7650434374809265  trainAcc state:  0.90625  \n",
            "epoch: 1 90 |||   loss type:   1.191906213760376  trainAcc type:   0.921875 |||  loss state 0.7993327975273132  trainAcc state:  0.953125  \n",
            "epoch: 1 95 |||   loss type:   1.1916381120681763  trainAcc type:   0.9375 |||  loss state 0.7822203636169434  trainAcc state:  0.953125  \n",
            "epoch: 1 100 |||   loss type:   1.1536422967910767  trainAcc type:   1.0 |||  loss state 0.7729825973510742  trainAcc state:  0.953125  \n",
            "epoch: 1 105 |||   loss type:   1.1252610683441162  trainAcc type:   0.921875 |||  loss state 0.7769114971160889  trainAcc state:  0.890625  \n",
            "epoch: 1 110 |||   loss type:   1.1617952585220337  trainAcc type:   0.953125 |||  loss state 0.7728366851806641  trainAcc state:  0.90625  \n",
            "epoch: 1 115 |||   loss type:   1.1486587524414062  trainAcc type:   0.84375 |||  loss state 0.7396818995475769  trainAcc state:  0.921875  \n",
            "epoch: 1 120 |||   loss type:   1.1192715167999268  trainAcc type:   0.984375 |||  loss state 0.737989068031311  trainAcc state:  0.984375  \n",
            "epoch: 1 125 |||   loss type:   1.1170750856399536  trainAcc type:   0.96875 |||  loss state 0.7684453725814819  trainAcc state:  0.890625  \n",
            "epoch: 1 130 |||   loss type:   1.0766143798828125  trainAcc type:   0.96875 |||  loss state 0.7380579710006714  trainAcc state:  0.890625  \n",
            "epoch: 1 135 |||   loss type:   1.064968228340149  trainAcc type:   0.953125 |||  loss state 0.660970151424408  trainAcc state:  0.96875  \n",
            "epoch: 1 140 |||   loss type:   1.0950151681900024  trainAcc type:   0.953125 |||  loss state 0.7097995281219482  trainAcc state:  0.96875  \n",
            "epoch: 1 145 |||   loss type:   1.106278896331787  trainAcc type:   0.921875 |||  loss state 0.702221155166626  trainAcc state:  0.953125  \n",
            "epoch: 1 |||   vloss type:   1.0828255414962769  validAcc type:   0.96875 |||  vloss state 0.7096671462059021  validAcc state:  0.9375  \n",
            "epoch: 1 |||   vloss type:   1.098030686378479  validAcc type:   0.921875 |||  vloss state 0.6971360445022583  validAcc state:  0.96875  \n",
            "epoch: 1 |||   vloss type:   1.087295651435852  validAcc type:   0.953125 |||  vloss state 0.6741622090339661  validAcc state:  0.984375  \n",
            "epoch: 1 |||   vloss type:   1.1104525327682495  validAcc type:   0.9375 |||  vloss state 0.6719892024993896  validAcc state:  0.96875  \n",
            "epoch: 1 |||   vloss type:   1.08876633644104  validAcc type:   0.9375 |||  vloss state 0.6953732967376709  validAcc state:  0.96875  \n",
            "epoch: 1 |||   vloss type:   1.051281452178955  validAcc type:   0.96875 |||  vloss state 0.7035932540893555  validAcc state:  0.953125  \n",
            "epoch: 1 |||   vloss type:   1.0757137537002563  validAcc type:   0.984375 |||  vloss state 0.7020981907844543  validAcc state:  0.890625  \n",
            "epoch: 1 |||   vloss type:   1.0847065448760986  validAcc type:   0.984375 |||  vloss state 0.6909503936767578  validAcc state:  0.984375  \n",
            "Time:     174.59078168869019\n",
            "epoch: 2 0 |||   loss type:   1.0780229568481445  trainAcc type:   0.984375 |||  loss state 0.713695228099823  trainAcc state:  0.96875  \n",
            "epoch: 2 5 |||   loss type:   1.0853973627090454  trainAcc type:   0.96875 |||  loss state 0.7074560523033142  trainAcc state:  0.953125  \n",
            "epoch: 2 10 |||   loss type:   1.0640909671783447  trainAcc type:   0.953125 |||  loss state 0.704628586769104  trainAcc state:  0.921875  \n",
            "epoch: 2 15 |||   loss type:   1.0612651109695435  trainAcc type:   0.921875 |||  loss state 0.6931139230728149  trainAcc state:  0.9375  \n",
            "epoch: 2 20 |||   loss type:   1.079447627067566  trainAcc type:   0.9375 |||  loss state 0.6422960162162781  trainAcc state:  0.984375  \n",
            "epoch: 2 25 |||   loss type:   1.0913541316986084  trainAcc type:   0.953125 |||  loss state 0.7009232044219971  trainAcc state:  0.921875  \n",
            "epoch: 2 30 |||   loss type:   1.0859769582748413  trainAcc type:   0.890625 |||  loss state 0.6707665324211121  trainAcc state:  1.0  \n",
            "epoch: 2 35 |||   loss type:   1.0500872135162354  trainAcc type:   0.96875 |||  loss state 0.6554635167121887  trainAcc state:  0.96875  \n",
            "epoch: 2 40 |||   loss type:   1.0858933925628662  trainAcc type:   0.875 |||  loss state 0.6520951986312866  trainAcc state:  1.0  \n",
            "epoch: 2 45 |||   loss type:   1.067154049873352  trainAcc type:   0.890625 |||  loss state 0.666145384311676  trainAcc state:  0.953125  \n",
            "epoch: 2 50 |||   loss type:   1.0535211563110352  trainAcc type:   0.984375 |||  loss state 0.6592977643013  trainAcc state:  0.96875  \n",
            "epoch: 2 55 |||   loss type:   1.0445785522460938  trainAcc type:   0.9375 |||  loss state 0.6757599711418152  trainAcc state:  0.953125  \n",
            "epoch: 2 60 |||   loss type:   1.024927020072937  trainAcc type:   0.96875 |||  loss state 0.6588061451911926  trainAcc state:  0.984375  \n",
            "epoch: 2 65 |||   loss type:   1.0107709169387817  trainAcc type:   0.984375 |||  loss state 0.6903690695762634  trainAcc state:  0.90625  \n",
            "epoch: 2 70 |||   loss type:   1.0250604152679443  trainAcc type:   0.984375 |||  loss state 0.6573233604431152  trainAcc state:  0.96875  \n",
            "epoch: 2 75 |||   loss type:   1.0456374883651733  trainAcc type:   0.953125 |||  loss state 0.6684661507606506  trainAcc state:  0.90625  \n",
            "epoch: 2 80 |||   loss type:   1.0769301652908325  trainAcc type:   0.90625 |||  loss state 0.658966064453125  trainAcc state:  0.921875  \n",
            "epoch: 2 85 |||   loss type:   1.0348575115203857  trainAcc type:   0.96875 |||  loss state 0.6756107211112976  trainAcc state:  0.953125  \n",
            "epoch: 2 90 |||   loss type:   1.0292985439300537  trainAcc type:   0.921875 |||  loss state 0.634583055973053  trainAcc state:  0.96875  \n",
            "epoch: 2 95 |||   loss type:   1.0298681259155273  trainAcc type:   0.96875 |||  loss state 0.6417575478553772  trainAcc state:  1.0  \n",
            "epoch: 2 100 |||   loss type:   1.01898992061615  trainAcc type:   0.953125 |||  loss state 0.6358813047409058  trainAcc state:  0.984375  \n",
            "epoch: 2 105 |||   loss type:   1.021762490272522  trainAcc type:   0.921875 |||  loss state 0.6053144335746765  trainAcc state:  1.0  \n",
            "epoch: 2 110 |||   loss type:   1.0166780948638916  trainAcc type:   0.984375 |||  loss state 0.6253084540367126  trainAcc state:  0.984375  \n",
            "epoch: 2 115 |||   loss type:   1.0072219371795654  trainAcc type:   0.96875 |||  loss state 0.6528838276863098  trainAcc state:  0.953125  \n",
            "epoch: 2 120 |||   loss type:   1.0247373580932617  trainAcc type:   0.953125 |||  loss state 0.653742253780365  trainAcc state:  0.953125  \n",
            "epoch: 2 125 |||   loss type:   0.9755306839942932  trainAcc type:   0.984375 |||  loss state 0.6136515140533447  trainAcc state:  0.96875  \n",
            "epoch: 2 130 |||   loss type:   1.0310051441192627  trainAcc type:   0.96875 |||  loss state 0.6438208818435669  trainAcc state:  0.9375  \n",
            "epoch: 2 135 |||   loss type:   0.9891385436058044  trainAcc type:   0.984375 |||  loss state 0.6291391253471375  trainAcc state:  0.984375  \n",
            "epoch: 2 140 |||   loss type:   1.0023566484451294  trainAcc type:   0.96875 |||  loss state 0.6538889408111572  trainAcc state:  0.96875  \n",
            "epoch: 2 145 |||   loss type:   1.0021249055862427  trainAcc type:   0.984375 |||  loss state 0.6353635787963867  trainAcc state:  0.953125  \n",
            "epoch: 2 |||   vloss type:   1.0090869665145874  validAcc type:   0.984375 |||  vloss state 0.6451374888420105  validAcc state:  0.96875  \n",
            "epoch: 2 |||   vloss type:   1.0180736780166626  validAcc type:   0.96875 |||  vloss state 0.6313802003860474  validAcc state:  0.96875  \n",
            "epoch: 2 |||   vloss type:   1.0037882328033447  validAcc type:   0.96875 |||  vloss state 0.6069558262825012  validAcc state:  0.984375  \n",
            "epoch: 2 |||   vloss type:   1.0279896259307861  validAcc type:   0.953125 |||  vloss state 0.6116154789924622  validAcc state:  0.984375  \n",
            "epoch: 2 |||   vloss type:   1.0104964971542358  validAcc type:   0.953125 |||  vloss state 0.6203581690788269  validAcc state:  0.984375  \n",
            "epoch: 2 |||   vloss type:   0.9712343215942383  validAcc type:   1.0 |||  vloss state 0.6374413371086121  validAcc state:  0.984375  \n",
            "epoch: 2 |||   vloss type:   0.9908495545387268  validAcc type:   1.0 |||  vloss state 0.6376139521598816  validAcc state:  0.96875  \n",
            "epoch: 2 |||   vloss type:   0.995151162147522  validAcc type:   1.0 |||  vloss state 0.6240897178649902  validAcc state:  0.96875  \n",
            "Time:     346.59091210365295\n",
            "epoch: 3 0 |||   loss type:   1.0081312656402588  trainAcc type:   0.984375 |||  loss state 0.6421555876731873  trainAcc state:  0.984375  \n",
            "epoch: 3 5 |||   loss type:   0.9831205606460571  trainAcc type:   0.984375 |||  loss state 0.6169518828392029  trainAcc state:  1.0  \n",
            "epoch: 3 10 |||   loss type:   1.0166231393814087  trainAcc type:   0.96875 |||  loss state 0.6058063507080078  trainAcc state:  1.0  \n",
            "epoch: 3 15 |||   loss type:   0.9945529699325562  trainAcc type:   0.984375 |||  loss state 0.6322965621948242  trainAcc state:  0.96875  \n",
            "epoch: 3 20 |||   loss type:   1.0276488065719604  trainAcc type:   0.9375 |||  loss state 0.6461403965950012  trainAcc state:  0.9375  \n",
            "epoch: 3 25 |||   loss type:   0.976452648639679  trainAcc type:   1.0 |||  loss state 0.6317088007926941  trainAcc state:  0.953125  \n",
            "epoch: 3 30 |||   loss type:   1.0035313367843628  trainAcc type:   0.96875 |||  loss state 0.6289954781532288  trainAcc state:  0.96875  \n",
            "epoch: 3 35 |||   loss type:   0.9868419170379639  trainAcc type:   1.0 |||  loss state 0.6500197649002075  trainAcc state:  0.921875  \n",
            "epoch: 3 40 |||   loss type:   0.9842936396598816  trainAcc type:   0.984375 |||  loss state 0.6379979252815247  trainAcc state:  0.921875  \n",
            "epoch: 3 45 |||   loss type:   0.9984793663024902  trainAcc type:   0.953125 |||  loss state 0.6250112056732178  trainAcc state:  0.984375  \n",
            "epoch: 3 50 |||   loss type:   0.9880884885787964  trainAcc type:   0.96875 |||  loss state 0.6193172931671143  trainAcc state:  0.96875  \n",
            "epoch: 3 55 |||   loss type:   0.999259889125824  trainAcc type:   0.96875 |||  loss state 0.6236849427223206  trainAcc state:  0.984375  \n",
            "epoch: 3 60 |||   loss type:   0.9853987097740173  trainAcc type:   0.984375 |||  loss state 0.6615774035453796  trainAcc state:  0.90625  \n",
            "epoch: 3 65 |||   loss type:   1.0095264911651611  trainAcc type:   0.953125 |||  loss state 0.6070838570594788  trainAcc state:  0.984375  \n",
            "epoch: 3 70 |||   loss type:   0.9729983806610107  trainAcc type:   0.96875 |||  loss state 0.6587459444999695  trainAcc state:  0.9375  \n",
            "epoch: 3 75 |||   loss type:   0.9771912693977356  trainAcc type:   0.984375 |||  loss state 0.5984836220741272  trainAcc state:  0.984375  \n",
            "epoch: 3 80 |||   loss type:   1.0061460733413696  trainAcc type:   0.96875 |||  loss state 0.6490248441696167  trainAcc state:  0.921875  \n",
            "epoch: 3 85 |||   loss type:   0.9633880853652954  trainAcc type:   0.984375 |||  loss state 0.6046894192695618  trainAcc state:  0.953125  \n",
            "epoch: 3 90 |||   loss type:   0.9785962700843811  trainAcc type:   0.984375 |||  loss state 0.6212340593338013  trainAcc state:  0.984375  \n",
            "epoch: 3 95 |||   loss type:   0.9772093296051025  trainAcc type:   0.96875 |||  loss state 0.6198606491088867  trainAcc state:  0.96875  \n",
            "epoch: 3 100 |||   loss type:   0.9655531644821167  trainAcc type:   0.984375 |||  loss state 0.5965072512626648  trainAcc state:  0.984375  \n",
            "epoch: 3 105 |||   loss type:   0.9806811809539795  trainAcc type:   0.953125 |||  loss state 0.6191829442977905  trainAcc state:  0.96875  \n",
            "epoch: 3 110 |||   loss type:   0.9739493131637573  trainAcc type:   0.984375 |||  loss state 0.6218960881233215  trainAcc state:  0.9375  \n",
            "epoch: 3 115 |||   loss type:   0.966865599155426  trainAcc type:   1.0 |||  loss state 0.6076918840408325  trainAcc state:  0.984375  \n",
            "epoch: 3 120 |||   loss type:   0.9664575457572937  trainAcc type:   0.953125 |||  loss state 0.6011943817138672  trainAcc state:  1.0  \n",
            "epoch: 3 125 |||   loss type:   0.9821628332138062  trainAcc type:   0.96875 |||  loss state 0.602219820022583  trainAcc state:  1.0  \n",
            "epoch: 3 130 |||   loss type:   0.9755842685699463  trainAcc type:   0.96875 |||  loss state 0.5968140363693237  trainAcc state:  1.0  \n",
            "epoch: 3 135 |||   loss type:   0.9899515509605408  trainAcc type:   0.953125 |||  loss state 0.6075103878974915  trainAcc state:  0.953125  \n",
            "epoch: 3 140 |||   loss type:   0.9846588373184204  trainAcc type:   0.96875 |||  loss state 0.6326723098754883  trainAcc state:  0.9375  \n",
            "epoch: 3 145 |||   loss type:   0.9424071311950684  trainAcc type:   0.984375 |||  loss state 0.6020044684410095  trainAcc state:  0.96875  \n",
            "epoch: 3 |||   vloss type:   0.9778763651847839  validAcc type:   1.0 |||  vloss state 0.623073160648346  validAcc state:  0.96875  \n",
            "epoch: 3 |||   vloss type:   0.9826814532279968  validAcc type:   0.984375 |||  vloss state 0.6100209951400757  validAcc state:  0.96875  \n",
            "epoch: 3 |||   vloss type:   0.9722900390625  validAcc type:   0.96875 |||  vloss state 0.5880293250083923  validAcc state:  1.0  \n",
            "epoch: 3 |||   vloss type:   0.9928168058395386  validAcc type:   0.953125 |||  vloss state 0.5925983786582947  validAcc state:  0.984375  \n",
            "epoch: 3 |||   vloss type:   0.975746750831604  validAcc type:   0.984375 |||  vloss state 0.6004621982574463  validAcc state:  0.984375  \n",
            "epoch: 3 |||   vloss type:   0.9460914134979248  validAcc type:   1.0 |||  vloss state 0.6176843047142029  validAcc state:  0.984375  \n",
            "epoch: 3 |||   vloss type:   0.9590979218482971  validAcc type:   1.0 |||  vloss state 0.6133302450180054  validAcc state:  0.984375  \n",
            "epoch: 3 |||   vloss type:   0.9585580229759216  validAcc type:   1.0 |||  vloss state 0.604572594165802  validAcc state:  0.96875  \n",
            "Time:     515.8945925235748\n",
            "epoch: 4 0 |||   loss type:   0.9780073165893555  trainAcc type:   1.0 |||  loss state 0.5964214205741882  trainAcc state:  0.984375  \n",
            "epoch: 4 5 |||   loss type:   0.9848622679710388  trainAcc type:   0.96875 |||  loss state 0.6127824187278748  trainAcc state:  0.96875  \n",
            "epoch: 4 10 |||   loss type:   0.978709876537323  trainAcc type:   0.921875 |||  loss state 0.5759275555610657  trainAcc state:  1.0  \n",
            "epoch: 4 15 |||   loss type:   0.9565820693969727  trainAcc type:   1.0 |||  loss state 0.6028815507888794  trainAcc state:  0.984375  \n",
            "epoch: 4 20 |||   loss type:   0.9694994688034058  trainAcc type:   0.984375 |||  loss state 0.5996087193489075  trainAcc state:  0.984375  \n",
            "epoch: 4 25 |||   loss type:   0.9556068181991577  trainAcc type:   1.0 |||  loss state 0.6392777562141418  trainAcc state:  0.921875  \n",
            "epoch: 4 30 |||   loss type:   0.960745096206665  trainAcc type:   0.96875 |||  loss state 0.6109966039657593  trainAcc state:  0.96875  \n",
            "epoch: 4 35 |||   loss type:   0.9721457362174988  trainAcc type:   0.96875 |||  loss state 0.6060407161712646  trainAcc state:  0.953125  \n",
            "epoch: 4 40 |||   loss type:   0.9691985845565796  trainAcc type:   0.953125 |||  loss state 0.6122312545776367  trainAcc state:  0.96875  \n",
            "epoch: 4 45 |||   loss type:   0.973710298538208  trainAcc type:   0.96875 |||  loss state 0.6145265698432922  trainAcc state:  0.96875  \n",
            "epoch: 4 50 |||   loss type:   0.9705820083618164  trainAcc type:   0.96875 |||  loss state 0.6162903308868408  trainAcc state:  0.953125  \n",
            "epoch: 4 55 |||   loss type:   0.9414359331130981  trainAcc type:   1.0 |||  loss state 0.6010404229164124  trainAcc state:  0.984375  \n",
            "epoch: 4 60 |||   loss type:   0.955674946308136  trainAcc type:   0.96875 |||  loss state 0.5937476754188538  trainAcc state:  1.0  \n",
            "epoch: 4 65 |||   loss type:   0.9610739350318909  trainAcc type:   1.0 |||  loss state 0.620151937007904  trainAcc state:  0.953125  \n",
            "epoch: 4 70 |||   loss type:   0.956200122833252  trainAcc type:   0.984375 |||  loss state 0.589396059513092  trainAcc state:  1.0  \n",
            "epoch: 4 75 |||   loss type:   0.9867190718650818  trainAcc type:   0.96875 |||  loss state 0.5930747985839844  trainAcc state:  0.96875  \n",
            "epoch: 4 80 |||   loss type:   0.9469261169433594  trainAcc type:   0.96875 |||  loss state 0.6025494337081909  trainAcc state:  0.984375  \n",
            "epoch: 4 85 |||   loss type:   0.9388740062713623  trainAcc type:   1.0 |||  loss state 0.5866685509681702  trainAcc state:  0.984375  \n",
            "epoch: 4 90 |||   loss type:   0.9475058913230896  trainAcc type:   0.984375 |||  loss state 0.5915125012397766  trainAcc state:  0.984375  \n",
            "epoch: 4 95 |||   loss type:   0.9901794195175171  trainAcc type:   0.921875 |||  loss state 0.5904959440231323  trainAcc state:  1.0  \n",
            "epoch: 4 100 |||   loss type:   0.9657731056213379  trainAcc type:   0.984375 |||  loss state 0.5924807190895081  trainAcc state:  0.984375  \n",
            "epoch: 4 105 |||   loss type:   0.9466277360916138  trainAcc type:   0.984375 |||  loss state 0.6228461265563965  trainAcc state:  0.953125  \n",
            "epoch: 4 110 |||   loss type:   0.9343594312667847  trainAcc type:   1.0 |||  loss state 0.6090800166130066  trainAcc state:  0.9375  \n",
            "epoch: 4 115 |||   loss type:   0.9684001207351685  trainAcc type:   0.96875 |||  loss state 0.5934979915618896  trainAcc state:  0.953125  \n",
            "epoch: 4 120 |||   loss type:   0.968073844909668  trainAcc type:   0.96875 |||  loss state 0.6073102951049805  trainAcc state:  0.984375  \n",
            "epoch: 4 125 |||   loss type:   0.9544441103935242  trainAcc type:   1.0 |||  loss state 0.6303744316101074  trainAcc state:  0.953125  \n",
            "epoch: 4 130 |||   loss type:   0.9678938388824463  trainAcc type:   0.984375 |||  loss state 0.582675576210022  trainAcc state:  1.0  \n",
            "epoch: 4 135 |||   loss type:   0.9700073003768921  trainAcc type:   0.953125 |||  loss state 0.5860986113548279  trainAcc state:  0.984375  \n",
            "epoch: 4 140 |||   loss type:   0.9602329730987549  trainAcc type:   0.984375 |||  loss state 0.5892588496208191  trainAcc state:  0.984375  \n",
            "epoch: 4 145 |||   loss type:   0.9528094530105591  trainAcc type:   1.0 |||  loss state 0.5800732970237732  trainAcc state:  1.0  \n",
            "epoch: 4 |||   vloss type:   0.9652434587478638  validAcc type:   1.0 |||  vloss state 0.6157770156860352  validAcc state:  0.96875  \n",
            "epoch: 4 |||   vloss type:   0.9671233892440796  validAcc type:   0.96875 |||  vloss state 0.600172758102417  validAcc state:  0.96875  \n",
            "epoch: 4 |||   vloss type:   0.9589592814445496  validAcc type:   0.984375 |||  vloss state 0.5793806314468384  validAcc state:  1.0  \n",
            "epoch: 4 |||   vloss type:   0.9825746417045593  validAcc type:   0.953125 |||  vloss state 0.587725818157196  validAcc state:  0.96875  \n",
            "epoch: 4 |||   vloss type:   0.9628629088401794  validAcc type:   0.984375 |||  vloss state 0.5883163809776306  validAcc state:  0.984375  \n",
            "epoch: 4 |||   vloss type:   0.9349116086959839  validAcc type:   1.0 |||  vloss state 0.6033180952072144  validAcc state:  1.0  \n",
            "epoch: 4 |||   vloss type:   0.9478104710578918  validAcc type:   1.0 |||  vloss state 0.6011437177658081  validAcc state:  0.984375  \n",
            "epoch: 4 |||   vloss type:   0.9487669467926025  validAcc type:   1.0 |||  vloss state 0.5917312502861023  validAcc state:  1.0  \n",
            "Time:     683.9999394416809\n",
            "epoch: 5 0 |||   loss type:   0.9334712624549866  trainAcc type:   1.0 |||  loss state 0.5977368354797363  trainAcc state:  0.953125  \n",
            "epoch: 5 5 |||   loss type:   0.959357500076294  trainAcc type:   0.953125 |||  loss state 0.5890475511550903  trainAcc state:  0.984375  \n",
            "epoch: 5 10 |||   loss type:   0.9314095973968506  trainAcc type:   1.0 |||  loss state 0.582859218120575  trainAcc state:  0.984375  \n",
            "epoch: 5 15 |||   loss type:   0.948498010635376  trainAcc type:   0.984375 |||  loss state 0.6185129880905151  trainAcc state:  0.9375  \n",
            "epoch: 5 20 |||   loss type:   0.9558588862419128  trainAcc type:   0.984375 |||  loss state 0.5789845585823059  trainAcc state:  1.0  \n",
            "epoch: 5 25 |||   loss type:   0.9827028512954712  trainAcc type:   0.984375 |||  loss state 0.6190391778945923  trainAcc state:  0.9375  \n",
            "epoch: 5 30 |||   loss type:   0.9407655000686646  trainAcc type:   1.0 |||  loss state 0.6230767369270325  trainAcc state:  0.953125  \n",
            "epoch: 5 35 |||   loss type:   0.9412918090820312  trainAcc type:   1.0 |||  loss state 0.5825222730636597  trainAcc state:  1.0  \n",
            "epoch: 5 40 |||   loss type:   0.986882209777832  trainAcc type:   0.96875 |||  loss state 0.5839078426361084  trainAcc state:  0.984375  \n",
            "epoch: 5 45 |||   loss type:   0.950194776058197  trainAcc type:   0.984375 |||  loss state 0.5772171020507812  trainAcc state:  0.984375  \n",
            "epoch: 5 50 |||   loss type:   0.9421923160552979  trainAcc type:   1.0 |||  loss state 0.5872094631195068  trainAcc state:  0.984375  \n",
            "epoch: 5 55 |||   loss type:   0.9583265781402588  trainAcc type:   0.953125 |||  loss state 0.5821614265441895  trainAcc state:  1.0  \n",
            "epoch: 5 60 |||   loss type:   0.9418359994888306  trainAcc type:   1.0 |||  loss state 0.5921841859817505  trainAcc state:  0.984375  \n",
            "epoch: 5 65 |||   loss type:   0.9450703263282776  trainAcc type:   1.0 |||  loss state 0.5910397171974182  trainAcc state:  0.984375  \n",
            "epoch: 5 70 |||   loss type:   0.968376100063324  trainAcc type:   1.0 |||  loss state 0.5960449576377869  trainAcc state:  0.984375  \n",
            "epoch: 5 75 |||   loss type:   0.9400443434715271  trainAcc type:   0.96875 |||  loss state 0.592491626739502  trainAcc state:  0.96875  \n",
            "epoch: 5 80 |||   loss type:   0.923679769039154  trainAcc type:   1.0 |||  loss state 0.5834670066833496  trainAcc state:  0.984375  \n",
            "epoch: 5 85 |||   loss type:   0.9740815162658691  trainAcc type:   0.953125 |||  loss state 0.5854619741439819  trainAcc state:  1.0  \n",
            "epoch: 5 90 |||   loss type:   0.9543332457542419  trainAcc type:   0.984375 |||  loss state 0.5842537879943848  trainAcc state:  0.96875  \n",
            "epoch: 5 95 |||   loss type:   0.9472225308418274  trainAcc type:   0.984375 |||  loss state 0.6160658597946167  trainAcc state:  0.96875  \n",
            "epoch: 5 100 |||   loss type:   0.9666616916656494  trainAcc type:   0.96875 |||  loss state 0.6022658348083496  trainAcc state:  0.984375  \n",
            "epoch: 5 105 |||   loss type:   0.9297330975532532  trainAcc type:   1.0 |||  loss state 0.6222681403160095  trainAcc state:  0.953125  \n",
            "epoch: 5 110 |||   loss type:   0.9483004808425903  trainAcc type:   0.984375 |||  loss state 0.6132343411445618  trainAcc state:  0.96875  \n",
            "epoch: 5 115 |||   loss type:   0.9421591758728027  trainAcc type:   0.96875 |||  loss state 0.5997203588485718  trainAcc state:  0.984375  \n",
            "epoch: 5 120 |||   loss type:   0.9555821418762207  trainAcc type:   0.96875 |||  loss state 0.5779274702072144  trainAcc state:  1.0  \n",
            "epoch: 5 125 |||   loss type:   0.9622217416763306  trainAcc type:   1.0 |||  loss state 0.5849035978317261  trainAcc state:  0.984375  \n",
            "epoch: 5 130 |||   loss type:   0.9560539722442627  trainAcc type:   0.984375 |||  loss state 0.582697868347168  trainAcc state:  0.984375  \n",
            "epoch: 5 135 |||   loss type:   0.9576390385627747  trainAcc type:   0.96875 |||  loss state 0.5909715294837952  trainAcc state:  0.96875  \n",
            "epoch: 5 140 |||   loss type:   0.9361647963523865  trainAcc type:   1.0 |||  loss state 0.5831544399261475  trainAcc state:  0.984375  \n",
            "epoch: 5 145 |||   loss type:   0.9385650157928467  trainAcc type:   0.953125 |||  loss state 0.6076425909996033  trainAcc state:  0.9375  \n",
            "epoch: 5 |||   vloss type:   0.9560924768447876  validAcc type:   1.0 |||  vloss state 0.6105809807777405  validAcc state:  0.96875  \n",
            "epoch: 5 |||   vloss type:   0.9517964124679565  validAcc type:   1.0 |||  vloss state 0.5919252634048462  validAcc state:  0.984375  \n",
            "epoch: 5 |||   vloss type:   0.9493687748908997  validAcc type:   0.984375 |||  vloss state 0.5751923322677612  validAcc state:  1.0  \n",
            "epoch: 5 |||   vloss type:   0.9689321517944336  validAcc type:   0.96875 |||  vloss state 0.5831385254859924  validAcc state:  0.96875  \n",
            "epoch: 5 |||   vloss type:   0.9528313875198364  validAcc type:   0.984375 |||  vloss state 0.5823262929916382  validAcc state:  0.984375  \n",
            "epoch: 5 |||   vloss type:   0.9288256764411926  validAcc type:   1.0 |||  vloss state 0.5970053672790527  validAcc state:  1.0  \n",
            "epoch: 5 |||   vloss type:   0.9361942410469055  validAcc type:   1.0 |||  vloss state 0.591864287853241  validAcc state:  0.984375  \n",
            "epoch: 5 |||   vloss type:   0.9355352520942688  validAcc type:   1.0 |||  vloss state 0.5880993604660034  validAcc state:  1.0  \n",
            "Time:     853.0076909065247\n",
            "epoch: 6 0 |||   loss type:   0.9437673091888428  trainAcc type:   1.0 |||  loss state 0.5823423266410828  trainAcc state:  1.0  \n",
            "epoch: 6 5 |||   loss type:   0.9468576908111572  trainAcc type:   1.0 |||  loss state 0.5784258246421814  trainAcc state:  1.0  \n",
            "epoch: 6 10 |||   loss type:   0.9527855515480042  trainAcc type:   0.984375 |||  loss state 0.5938786864280701  trainAcc state:  1.0  \n",
            "epoch: 6 15 |||   loss type:   0.9443572759628296  trainAcc type:   0.984375 |||  loss state 0.571976900100708  trainAcc state:  1.0  \n",
            "epoch: 6 20 |||   loss type:   0.9452510476112366  trainAcc type:   1.0 |||  loss state 0.582506537437439  trainAcc state:  0.984375  \n",
            "epoch: 6 25 |||   loss type:   0.9349532127380371  trainAcc type:   0.96875 |||  loss state 0.5717021822929382  trainAcc state:  1.0  \n",
            "epoch: 6 30 |||   loss type:   0.9517489671707153  trainAcc type:   0.984375 |||  loss state 0.5874027609825134  trainAcc state:  0.96875  \n",
            "epoch: 6 35 |||   loss type:   0.9322211146354675  trainAcc type:   1.0 |||  loss state 0.5926081538200378  trainAcc state:  0.96875  \n",
            "epoch: 6 40 |||   loss type:   0.9486687779426575  trainAcc type:   1.0 |||  loss state 0.5889617204666138  trainAcc state:  0.984375  \n",
            "epoch: 6 45 |||   loss type:   0.9501327276229858  trainAcc type:   0.984375 |||  loss state 0.5778926610946655  trainAcc state:  1.0  \n",
            "epoch: 6 50 |||   loss type:   0.9544239640235901  trainAcc type:   0.96875 |||  loss state 0.5728722214698792  trainAcc state:  0.984375  \n",
            "epoch: 6 55 |||   loss type:   0.9587990045547485  trainAcc type:   0.984375 |||  loss state 0.5950890183448792  trainAcc state:  0.984375  \n",
            "epoch: 6 60 |||   loss type:   0.9367757439613342  trainAcc type:   0.984375 |||  loss state 0.5810406804084778  trainAcc state:  0.984375  \n",
            "epoch: 6 65 |||   loss type:   0.9387238025665283  trainAcc type:   0.984375 |||  loss state 0.5886327624320984  trainAcc state:  1.0  \n",
            "epoch: 6 70 |||   loss type:   0.9229447245597839  trainAcc type:   1.0 |||  loss state 0.5878863334655762  trainAcc state:  0.984375  \n",
            "epoch: 6 75 |||   loss type:   0.9420585632324219  trainAcc type:   1.0 |||  loss state 0.5891408324241638  trainAcc state:  0.984375  \n",
            "epoch: 6 80 |||   loss type:   0.9392741918563843  trainAcc type:   0.984375 |||  loss state 0.5814082622528076  trainAcc state:  1.0  \n",
            "epoch: 6 85 |||   loss type:   0.9586973786354065  trainAcc type:   0.96875 |||  loss state 0.5829627513885498  trainAcc state:  1.0  \n",
            "epoch: 6 90 |||   loss type:   0.9340546727180481  trainAcc type:   1.0 |||  loss state 0.5854059457778931  trainAcc state:  0.984375  \n",
            "epoch: 6 95 |||   loss type:   0.9299418926239014  trainAcc type:   1.0 |||  loss state 0.5830647349357605  trainAcc state:  0.984375  \n",
            "epoch: 6 100 |||   loss type:   0.9490081667900085  trainAcc type:   1.0 |||  loss state 0.5815595984458923  trainAcc state:  0.984375  \n",
            "epoch: 6 105 |||   loss type:   0.945083498954773  trainAcc type:   0.96875 |||  loss state 0.5837269425392151  trainAcc state:  0.984375  \n",
            "epoch: 6 110 |||   loss type:   0.9435673952102661  trainAcc type:   0.96875 |||  loss state 0.596234142780304  trainAcc state:  0.984375  \n",
            "epoch: 6 115 |||   loss type:   0.9195992946624756  trainAcc type:   1.0 |||  loss state 0.5753258466720581  trainAcc state:  0.984375  \n",
            "epoch: 6 120 |||   loss type:   0.9303538203239441  trainAcc type:   1.0 |||  loss state 0.5805433988571167  trainAcc state:  0.984375  \n",
            "epoch: 6 125 |||   loss type:   0.9314979910850525  trainAcc type:   1.0 |||  loss state 0.5904915928840637  trainAcc state:  0.96875  \n",
            "epoch: 6 130 |||   loss type:   0.9299978613853455  trainAcc type:   1.0 |||  loss state 0.5834448337554932  trainAcc state:  0.96875  \n",
            "epoch: 6 135 |||   loss type:   0.9455035924911499  trainAcc type:   1.0 |||  loss state 0.5874536037445068  trainAcc state:  0.984375  \n",
            "epoch: 6 140 |||   loss type:   0.9360421895980835  trainAcc type:   1.0 |||  loss state 0.5828397274017334  trainAcc state:  0.984375  \n",
            "epoch: 6 145 |||   loss type:   0.9300547242164612  trainAcc type:   0.96875 |||  loss state 0.5898020267486572  trainAcc state:  0.984375  \n",
            "epoch: 6 |||   vloss type:   0.948494553565979  validAcc type:   0.984375 |||  vloss state 0.6058353185653687  validAcc state:  0.953125  \n",
            "epoch: 6 |||   vloss type:   0.9434959292411804  validAcc type:   1.0 |||  vloss state 0.584956705570221  validAcc state:  1.0  \n",
            "epoch: 6 |||   vloss type:   0.9435206651687622  validAcc type:   0.984375 |||  vloss state 0.5713680982589722  validAcc state:  1.0  \n",
            "epoch: 6 |||   vloss type:   0.9597818851470947  validAcc type:   0.96875 |||  vloss state 0.5789917707443237  validAcc state:  0.96875  \n",
            "epoch: 6 |||   vloss type:   0.9448301792144775  validAcc type:   0.984375 |||  vloss state 0.578190803527832  validAcc state:  0.984375  \n",
            "epoch: 6 |||   vloss type:   0.9233589768409729  validAcc type:   1.0 |||  vloss state 0.5901464223861694  validAcc state:  1.0  \n",
            "epoch: 6 |||   vloss type:   0.929277777671814  validAcc type:   1.0 |||  vloss state 0.5849951505661011  validAcc state:  0.984375  \n",
            "epoch: 6 |||   vloss type:   0.9292928576469421  validAcc type:   1.0 |||  vloss state 0.5822807550430298  validAcc state:  1.0  \n",
            "Time:     1021.8554928302765\n",
            "epoch: 7 0 |||   loss type:   0.9343802332878113  trainAcc type:   1.0 |||  loss state 0.5753198862075806  trainAcc state:  1.0  \n",
            "epoch: 7 5 |||   loss type:   0.942436158657074  trainAcc type:   1.0 |||  loss state 0.5744278430938721  trainAcc state:  0.984375  \n",
            "epoch: 7 10 |||   loss type:   0.9275248646736145  trainAcc type:   1.0 |||  loss state 0.5865068435668945  trainAcc state:  0.96875  \n",
            "epoch: 7 15 |||   loss type:   0.9418625235557556  trainAcc type:   0.984375 |||  loss state 0.585918128490448  trainAcc state:  1.0  \n",
            "epoch: 7 20 |||   loss type:   0.9374229907989502  trainAcc type:   1.0 |||  loss state 0.6076282858848572  trainAcc state:  0.953125  \n",
            "epoch: 7 25 |||   loss type:   0.9295271039009094  trainAcc type:   1.0 |||  loss state 0.583085834980011  trainAcc state:  1.0  \n",
            "epoch: 7 30 |||   loss type:   0.935242772102356  trainAcc type:   1.0 |||  loss state 0.5757347941398621  trainAcc state:  0.984375  \n",
            "epoch: 7 35 |||   loss type:   0.9391556978225708  trainAcc type:   1.0 |||  loss state 0.6010273694992065  trainAcc state:  0.953125  \n",
            "epoch: 7 40 |||   loss type:   0.9322710633277893  trainAcc type:   0.96875 |||  loss state 0.5753418207168579  trainAcc state:  1.0  \n",
            "epoch: 7 45 |||   loss type:   0.9457646012306213  trainAcc type:   0.984375 |||  loss state 0.5658220052719116  trainAcc state:  1.0  \n",
            "epoch: 7 50 |||   loss type:   0.9185613393783569  trainAcc type:   1.0 |||  loss state 0.5839847326278687  trainAcc state:  0.984375  \n",
            "epoch: 7 55 |||   loss type:   0.9297007918357849  trainAcc type:   0.984375 |||  loss state 0.6003989577293396  trainAcc state:  0.953125  \n",
            "epoch: 7 60 |||   loss type:   0.9466742277145386  trainAcc type:   0.984375 |||  loss state 0.5750465393066406  trainAcc state:  1.0  \n",
            "epoch: 7 65 |||   loss type:   0.9535678625106812  trainAcc type:   0.984375 |||  loss state 0.6022456288337708  trainAcc state:  0.984375  \n",
            "epoch: 7 70 |||   loss type:   0.9394996166229248  trainAcc type:   0.984375 |||  loss state 0.5837639570236206  trainAcc state:  1.0  \n",
            "epoch: 7 75 |||   loss type:   0.939863920211792  trainAcc type:   0.96875 |||  loss state 0.5903074145317078  trainAcc state:  0.984375  \n",
            "epoch: 7 80 |||   loss type:   0.9257162809371948  trainAcc type:   0.984375 |||  loss state 0.6008741855621338  trainAcc state:  0.953125  \n",
            "epoch: 7 85 |||   loss type:   0.9317931532859802  trainAcc type:   1.0 |||  loss state 0.5891246795654297  trainAcc state:  0.984375  \n",
            "epoch: 7 90 |||   loss type:   0.9373412132263184  trainAcc type:   1.0 |||  loss state 0.5877864360809326  trainAcc state:  1.0  \n",
            "epoch: 7 95 |||   loss type:   0.9549195170402527  trainAcc type:   0.953125 |||  loss state 0.5681401491165161  trainAcc state:  1.0  \n",
            "epoch: 7 100 |||   loss type:   0.9617487788200378  trainAcc type:   0.953125 |||  loss state 0.5737295746803284  trainAcc state:  1.0  \n",
            "epoch: 7 105 |||   loss type:   0.9225464463233948  trainAcc type:   1.0 |||  loss state 0.5754446983337402  trainAcc state:  1.0  \n",
            "epoch: 7 110 |||   loss type:   0.9280874133110046  trainAcc type:   1.0 |||  loss state 0.5773321986198425  trainAcc state:  1.0  \n",
            "epoch: 7 115 |||   loss type:   0.9260345101356506  trainAcc type:   1.0 |||  loss state 0.5798749327659607  trainAcc state:  0.984375  \n",
            "epoch: 7 120 |||   loss type:   0.9390747547149658  trainAcc type:   1.0 |||  loss state 0.5883232355117798  trainAcc state:  0.96875  \n",
            "epoch: 7 125 |||   loss type:   0.9370846748352051  trainAcc type:   0.984375 |||  loss state 0.5774575471878052  trainAcc state:  0.984375  \n",
            "epoch: 7 130 |||   loss type:   0.933387041091919  trainAcc type:   1.0 |||  loss state 0.5723329782485962  trainAcc state:  1.0  \n",
            "epoch: 7 135 |||   loss type:   0.9391327500343323  trainAcc type:   1.0 |||  loss state 0.5854886770248413  trainAcc state:  1.0  \n",
            "epoch: 7 140 |||   loss type:   0.9419204592704773  trainAcc type:   0.984375 |||  loss state 0.5877482891082764  trainAcc state:  0.984375  \n",
            "epoch: 7 145 |||   loss type:   0.9234756231307983  trainAcc type:   1.0 |||  loss state 0.5759736895561218  trainAcc state:  0.984375  \n",
            "epoch: 7 |||   vloss type:   0.9459148049354553  validAcc type:   0.984375 |||  vloss state 0.604249119758606  validAcc state:  0.96875  \n",
            "epoch: 7 |||   vloss type:   0.9407482743263245  validAcc type:   1.0 |||  vloss state 0.5832540392875671  validAcc state:  0.984375  \n",
            "epoch: 7 |||   vloss type:   0.9423369765281677  validAcc type:   1.0 |||  vloss state 0.5724222660064697  validAcc state:  1.0  \n",
            "epoch: 7 |||   vloss type:   0.958017110824585  validAcc type:   0.984375 |||  vloss state 0.5778881907463074  validAcc state:  0.984375  \n",
            "epoch: 7 |||   vloss type:   0.9443374872207642  validAcc type:   0.984375 |||  vloss state 0.5764026045799255  validAcc state:  1.0  \n",
            "epoch: 7 |||   vloss type:   0.9219563007354736  validAcc type:   1.0 |||  vloss state 0.587738573551178  validAcc state:  1.0  \n",
            "epoch: 7 |||   vloss type:   0.9282298684120178  validAcc type:   1.0 |||  vloss state 0.5823237299919128  validAcc state:  0.984375  \n",
            "epoch: 7 |||   vloss type:   0.9293231964111328  validAcc type:   1.0 |||  vloss state 0.5803767442703247  validAcc state:  1.0  \n",
            "Time:     1190.5246810913086\n",
            "epoch: 8 0 |||   loss type:   0.9260790348052979  trainAcc type:   1.0 |||  loss state 0.574891209602356  trainAcc state:  1.0  \n",
            "epoch: 8 5 |||   loss type:   0.9552607536315918  trainAcc type:   0.984375 |||  loss state 0.580809473991394  trainAcc state:  1.0  \n",
            "epoch: 8 10 |||   loss type:   0.9416882991790771  trainAcc type:   0.984375 |||  loss state 0.5823962688446045  trainAcc state:  0.96875  \n",
            "epoch: 8 15 |||   loss type:   0.9265341758728027  trainAcc type:   1.0 |||  loss state 0.5749086141586304  trainAcc state:  1.0  \n",
            "epoch: 8 20 |||   loss type:   0.940863311290741  trainAcc type:   0.984375 |||  loss state 0.6158831715583801  trainAcc state:  0.96875  \n",
            "epoch: 8 25 |||   loss type:   0.9404718279838562  trainAcc type:   0.96875 |||  loss state 0.5775178670883179  trainAcc state:  1.0  \n",
            "epoch: 8 30 |||   loss type:   0.9328666925430298  trainAcc type:   1.0 |||  loss state 0.5777020454406738  trainAcc state:  0.984375  \n",
            "epoch: 8 35 |||   loss type:   0.9264209270477295  trainAcc type:   1.0 |||  loss state 0.5911970734596252  trainAcc state:  0.96875  \n",
            "epoch: 8 40 |||   loss type:   0.9207399487495422  trainAcc type:   1.0 |||  loss state 0.5691857933998108  trainAcc state:  0.984375  \n",
            "epoch: 8 45 |||   loss type:   0.9310270547866821  trainAcc type:   1.0 |||  loss state 0.5736013054847717  trainAcc state:  1.0  \n",
            "epoch: 8 50 |||   loss type:   0.9245918989181519  trainAcc type:   1.0 |||  loss state 0.6054818034172058  trainAcc state:  0.9375  \n",
            "epoch: 8 55 |||   loss type:   0.9355480670928955  trainAcc type:   1.0 |||  loss state 0.5850867033004761  trainAcc state:  0.96875  \n",
            "epoch: 8 60 |||   loss type:   0.9285895824432373  trainAcc type:   0.984375 |||  loss state 0.5901442766189575  trainAcc state:  0.984375  \n",
            "epoch: 8 65 |||   loss type:   0.9245321154594421  trainAcc type:   1.0 |||  loss state 0.5751515030860901  trainAcc state:  1.0  \n",
            "epoch: 8 70 |||   loss type:   0.9213442206382751  trainAcc type:   1.0 |||  loss state 0.568156361579895  trainAcc state:  1.0  \n",
            "epoch: 8 75 |||   loss type:   0.9371199011802673  trainAcc type:   1.0 |||  loss state 0.5708459615707397  trainAcc state:  0.984375  \n",
            "epoch: 8 80 |||   loss type:   0.943689227104187  trainAcc type:   0.96875 |||  loss state 0.5627456307411194  trainAcc state:  1.0  \n",
            "epoch: 8 85 |||   loss type:   0.9149875640869141  trainAcc type:   1.0 |||  loss state 0.5851455926895142  trainAcc state:  0.96875  \n",
            "epoch: 8 90 |||   loss type:   0.9238285422325134  trainAcc type:   1.0 |||  loss state 0.5776469707489014  trainAcc state:  0.984375  \n",
            "epoch: 8 95 |||   loss type:   0.9249733686447144  trainAcc type:   0.984375 |||  loss state 0.5623748302459717  trainAcc state:  1.0  \n",
            "epoch: 8 100 |||   loss type:   0.9205811023712158  trainAcc type:   1.0 |||  loss state 0.5691525340080261  trainAcc state:  1.0  \n",
            "epoch: 8 105 |||   loss type:   0.9222548604011536  trainAcc type:   1.0 |||  loss state 0.5618280172348022  trainAcc state:  1.0  \n",
            "epoch: 8 110 |||   loss type:   0.940224826335907  trainAcc type:   0.984375 |||  loss state 0.578219473361969  trainAcc state:  0.984375  \n",
            "epoch: 8 115 |||   loss type:   0.9264746904373169  trainAcc type:   1.0 |||  loss state 0.5640178322792053  trainAcc state:  1.0  \n",
            "epoch: 8 120 |||   loss type:   0.9193975925445557  trainAcc type:   1.0 |||  loss state 0.5743504762649536  trainAcc state:  0.984375  \n",
            "epoch: 8 125 |||   loss type:   0.9344931840896606  trainAcc type:   0.96875 |||  loss state 0.565666139125824  trainAcc state:  1.0  \n",
            "epoch: 8 130 |||   loss type:   0.9369374513626099  trainAcc type:   0.984375 |||  loss state 0.5678903460502625  trainAcc state:  1.0  \n",
            "epoch: 8 135 |||   loss type:   0.9348220229148865  trainAcc type:   1.0 |||  loss state 0.574984610080719  trainAcc state:  0.984375  \n",
            "epoch: 8 140 |||   loss type:   0.9193302392959595  trainAcc type:   1.0 |||  loss state 0.5718498826026917  trainAcc state:  0.984375  \n",
            "epoch: 8 145 |||   loss type:   0.9458304047584534  trainAcc type:   1.0 |||  loss state 0.58463454246521  trainAcc state:  0.96875  \n",
            "epoch: 8 |||   vloss type:   0.93852299451828  validAcc type:   0.984375 |||  vloss state 0.6039178371429443  validAcc state:  0.953125  \n",
            "epoch: 8 |||   vloss type:   0.9333251714706421  validAcc type:   1.0 |||  vloss state 0.5759264826774597  validAcc state:  1.0  \n",
            "epoch: 8 |||   vloss type:   0.9360573291778564  validAcc type:   1.0 |||  vloss state 0.5684472918510437  validAcc state:  1.0  \n",
            "epoch: 8 |||   vloss type:   0.9490514397621155  validAcc type:   0.984375 |||  vloss state 0.575033962726593  validAcc state:  0.96875  \n",
            "epoch: 8 |||   vloss type:   0.9359458088874817  validAcc type:   0.984375 |||  vloss state 0.5719085931777954  validAcc state:  0.984375  \n",
            "epoch: 8 |||   vloss type:   0.9180117845535278  validAcc type:   1.0 |||  vloss state 0.583676815032959  validAcc state:  1.0  \n",
            "epoch: 8 |||   vloss type:   0.9209588170051575  validAcc type:   1.0 |||  vloss state 0.5769659876823425  validAcc state:  1.0  \n",
            "epoch: 8 |||   vloss type:   0.9212048053741455  validAcc type:   1.0 |||  vloss state 0.575517475605011  validAcc state:  1.0  \n",
            "Time:     1360.1397104263306\n",
            "epoch: 9 0 |||   loss type:   0.9291760921478271  trainAcc type:   1.0 |||  loss state 0.5829489231109619  trainAcc state:  0.984375  \n",
            "epoch: 9 5 |||   loss type:   0.919323742389679  trainAcc type:   1.0 |||  loss state 0.5698321461677551  trainAcc state:  1.0  \n",
            "epoch: 9 10 |||   loss type:   0.9422930479049683  trainAcc type:   0.96875 |||  loss state 0.5750547051429749  trainAcc state:  1.0  \n",
            "epoch: 9 15 |||   loss type:   0.9197072982788086  trainAcc type:   1.0 |||  loss state 0.5645012259483337  trainAcc state:  1.0  \n",
            "epoch: 9 20 |||   loss type:   0.9212949275970459  trainAcc type:   1.0 |||  loss state 0.5645598769187927  trainAcc state:  1.0  \n",
            "epoch: 9 25 |||   loss type:   0.9266996383666992  trainAcc type:   1.0 |||  loss state 0.5650387406349182  trainAcc state:  1.0  \n",
            "epoch: 9 30 |||   loss type:   0.9208410382270813  trainAcc type:   1.0 |||  loss state 0.5677749514579773  trainAcc state:  1.0  \n",
            "epoch: 9 35 |||   loss type:   0.9256126880645752  trainAcc type:   1.0 |||  loss state 0.5793412923812866  trainAcc state:  0.984375  \n",
            "epoch: 9 40 |||   loss type:   0.9331751465797424  trainAcc type:   1.0 |||  loss state 0.5644106268882751  trainAcc state:  1.0  \n",
            "epoch: 9 45 |||   loss type:   0.9270097017288208  trainAcc type:   1.0 |||  loss state 0.5936145782470703  trainAcc state:  0.96875  \n",
            "epoch: 9 50 |||   loss type:   0.9367076754570007  trainAcc type:   0.984375 |||  loss state 0.5897066593170166  trainAcc state:  0.953125  \n",
            "epoch: 9 55 |||   loss type:   0.9405772686004639  trainAcc type:   0.984375 |||  loss state 0.5722025036811829  trainAcc state:  1.0  \n",
            "epoch: 9 60 |||   loss type:   0.9251105785369873  trainAcc type:   1.0 |||  loss state 0.57069993019104  trainAcc state:  1.0  \n",
            "epoch: 9 65 |||   loss type:   0.9192143082618713  trainAcc type:   1.0 |||  loss state 0.5803039073944092  trainAcc state:  1.0  \n",
            "epoch: 9 70 |||   loss type:   0.9306710958480835  trainAcc type:   1.0 |||  loss state 0.5656638741493225  trainAcc state:  1.0  \n",
            "epoch: 9 75 |||   loss type:   0.9275999069213867  trainAcc type:   1.0 |||  loss state 0.5743175148963928  trainAcc state:  1.0  \n",
            "epoch: 9 80 |||   loss type:   0.928339958190918  trainAcc type:   0.984375 |||  loss state 0.5799305438995361  trainAcc state:  1.0  \n",
            "epoch: 9 85 |||   loss type:   0.9438274502754211  trainAcc type:   0.984375 |||  loss state 0.5777397751808167  trainAcc state:  1.0  \n",
            "epoch: 9 90 |||   loss type:   0.9279292821884155  trainAcc type:   0.984375 |||  loss state 0.5763241052627563  trainAcc state:  0.984375  \n",
            "epoch: 9 95 |||   loss type:   0.9283393621444702  trainAcc type:   0.96875 |||  loss state 0.565891683101654  trainAcc state:  1.0  \n",
            "epoch: 9 100 |||   loss type:   0.927636444568634  trainAcc type:   0.984375 |||  loss state 0.5835953950881958  trainAcc state:  0.984375  \n",
            "epoch: 9 105 |||   loss type:   0.9254562854766846  trainAcc type:   0.984375 |||  loss state 0.5735799074172974  trainAcc state:  1.0  \n",
            "epoch: 9 110 |||   loss type:   0.9325534105300903  trainAcc type:   0.96875 |||  loss state 0.5718392133712769  trainAcc state:  0.984375  \n",
            "epoch: 9 115 |||   loss type:   0.9276586174964905  trainAcc type:   1.0 |||  loss state 0.5928001403808594  trainAcc state:  0.984375  \n",
            "epoch: 9 120 |||   loss type:   0.9219216108322144  trainAcc type:   1.0 |||  loss state 0.5942074656486511  trainAcc state:  0.984375  \n",
            "epoch: 9 125 |||   loss type:   0.9346047639846802  trainAcc type:   0.96875 |||  loss state 0.5913645029067993  trainAcc state:  0.984375  \n",
            "epoch: 9 130 |||   loss type:   0.9335974454879761  trainAcc type:   1.0 |||  loss state 0.5662749409675598  trainAcc state:  1.0  \n",
            "epoch: 9 135 |||   loss type:   0.9326115250587463  trainAcc type:   0.984375 |||  loss state 0.5731545686721802  trainAcc state:  1.0  \n",
            "epoch: 9 140 |||   loss type:   0.9264930486679077  trainAcc type:   0.984375 |||  loss state 0.5657063126564026  trainAcc state:  1.0  \n",
            "epoch: 9 145 |||   loss type:   0.921906590461731  trainAcc type:   1.0 |||  loss state 0.5661922693252563  trainAcc state:  1.0  \n",
            "epoch: 9 |||   vloss type:   0.9378937482833862  validAcc type:   0.984375 |||  vloss state 0.6033872961997986  validAcc state:  0.953125  \n",
            "epoch: 9 |||   vloss type:   0.9310132265090942  validAcc type:   1.0 |||  vloss state 0.5748322010040283  validAcc state:  1.0  \n",
            "epoch: 9 |||   vloss type:   0.9357498288154602  validAcc type:   1.0 |||  vloss state 0.5678507089614868  validAcc state:  1.0  \n",
            "epoch: 9 |||   vloss type:   0.9483841061592102  validAcc type:   0.984375 |||  vloss state 0.5759807825088501  validAcc state:  0.96875  \n",
            "epoch: 9 |||   vloss type:   0.9349300265312195  validAcc type:   0.984375 |||  vloss state 0.5724831223487854  validAcc state:  0.984375  \n",
            "epoch: 9 |||   vloss type:   0.9175321459770203  validAcc type:   1.0 |||  vloss state 0.583652138710022  validAcc state:  1.0  \n",
            "epoch: 9 |||   vloss type:   0.9202826023101807  validAcc type:   1.0 |||  vloss state 0.5757697224617004  validAcc state:  1.0  \n",
            "epoch: 9 |||   vloss type:   0.9220686554908752  validAcc type:   1.0 |||  vloss state 0.5741771459579468  validAcc state:  1.0  \n",
            "Time:     1529.0669581890106\n",
            "epoch: 10 0 |||   loss type:   0.9234781265258789  trainAcc type:   1.0 |||  loss state 0.5717387795448303  trainAcc state:  1.0  \n",
            "epoch: 10 5 |||   loss type:   0.9290416836738586  trainAcc type:   1.0 |||  loss state 0.5634190440177917  trainAcc state:  1.0  \n",
            "epoch: 10 10 |||   loss type:   0.9247553944587708  trainAcc type:   1.0 |||  loss state 0.5647645592689514  trainAcc state:  1.0  \n",
            "epoch: 10 15 |||   loss type:   0.9186040759086609  trainAcc type:   1.0 |||  loss state 0.5682266354560852  trainAcc state:  1.0  \n",
            "epoch: 10 20 |||   loss type:   0.9413596391677856  trainAcc type:   0.96875 |||  loss state 0.5668799877166748  trainAcc state:  1.0  \n",
            "epoch: 10 25 |||   loss type:   0.9249008893966675  trainAcc type:   1.0 |||  loss state 0.5739374756813049  trainAcc state:  0.984375  \n",
            "epoch: 10 30 |||   loss type:   0.9108586311340332  trainAcc type:   1.0 |||  loss state 0.5620308518409729  trainAcc state:  1.0  \n",
            "epoch: 10 35 |||   loss type:   0.9178923964500427  trainAcc type:   1.0 |||  loss state 0.5661102533340454  trainAcc state:  1.0  \n",
            "epoch: 10 40 |||   loss type:   0.9292816519737244  trainAcc type:   1.0 |||  loss state 0.5771362781524658  trainAcc state:  0.984375  \n",
            "epoch: 10 45 |||   loss type:   0.9366563558578491  trainAcc type:   0.984375 |||  loss state 0.5931022763252258  trainAcc state:  0.96875  \n",
            "epoch: 10 50 |||   loss type:   0.9222676753997803  trainAcc type:   1.0 |||  loss state 0.5695151090621948  trainAcc state:  1.0  \n",
            "epoch: 10 55 |||   loss type:   0.9209966063499451  trainAcc type:   1.0 |||  loss state 0.5798999071121216  trainAcc state:  0.984375  \n",
            "epoch: 10 60 |||   loss type:   0.9373080730438232  trainAcc type:   0.96875 |||  loss state 0.5859577655792236  trainAcc state:  0.96875  \n",
            "epoch: 10 65 |||   loss type:   0.9395864605903625  trainAcc type:   1.0 |||  loss state 0.5776203870773315  trainAcc state:  0.96875  \n",
            "epoch: 10 70 |||   loss type:   0.9195245504379272  trainAcc type:   1.0 |||  loss state 0.5683109760284424  trainAcc state:  1.0  \n",
            "epoch: 10 75 |||   loss type:   0.9261161088943481  trainAcc type:   0.984375 |||  loss state 0.5752935409545898  trainAcc state:  0.984375  \n",
            "epoch: 10 80 |||   loss type:   0.9229518175125122  trainAcc type:   1.0 |||  loss state 0.5678321719169617  trainAcc state:  1.0  \n",
            "epoch: 10 85 |||   loss type:   0.9280821681022644  trainAcc type:   1.0 |||  loss state 0.5742162466049194  trainAcc state:  1.0  \n",
            "epoch: 10 90 |||   loss type:   0.9166172742843628  trainAcc type:   1.0 |||  loss state 0.5833479166030884  trainAcc state:  0.984375  \n",
            "epoch: 10 95 |||   loss type:   0.9212323427200317  trainAcc type:   1.0 |||  loss state 0.5743077993392944  trainAcc state:  1.0  \n",
            "epoch: 10 100 |||   loss type:   0.9256779551506042  trainAcc type:   0.96875 |||  loss state 0.5625841617584229  trainAcc state:  1.0  \n",
            "epoch: 10 105 |||   loss type:   0.9208269119262695  trainAcc type:   1.0 |||  loss state 0.5823884010314941  trainAcc state:  0.984375  \n",
            "epoch: 10 110 |||   loss type:   0.9247525334358215  trainAcc type:   1.0 |||  loss state 0.5619156360626221  trainAcc state:  1.0  \n",
            "epoch: 10 115 |||   loss type:   0.9282353520393372  trainAcc type:   1.0 |||  loss state 0.5714078545570374  trainAcc state:  1.0  \n",
            "epoch: 10 120 |||   loss type:   0.9243074059486389  trainAcc type:   0.984375 |||  loss state 0.5681573152542114  trainAcc state:  1.0  \n",
            "epoch: 10 125 |||   loss type:   0.9341010451316833  trainAcc type:   1.0 |||  loss state 0.5699565410614014  trainAcc state:  1.0  \n",
            "epoch: 10 130 |||   loss type:   0.922953188419342  trainAcc type:   0.984375 |||  loss state 0.5758559703826904  trainAcc state:  0.984375  \n",
            "epoch: 10 135 |||   loss type:   0.9163679480552673  trainAcc type:   1.0 |||  loss state 0.5976582169532776  trainAcc state:  0.96875  \n",
            "epoch: 10 140 |||   loss type:   0.9440981149673462  trainAcc type:   0.984375 |||  loss state 0.5746965408325195  trainAcc state:  1.0  \n",
            "epoch: 10 145 |||   loss type:   0.9165648221969604  trainAcc type:   1.0 |||  loss state 0.5985208749771118  trainAcc state:  0.953125  \n",
            "epoch: 10 |||   vloss type:   0.9359053373336792  validAcc type:   0.984375 |||  vloss state 0.5973504781723022  validAcc state:  0.953125  \n",
            "epoch: 10 |||   vloss type:   0.9298867583274841  validAcc type:   1.0 |||  vloss state 0.5733043551445007  validAcc state:  1.0  \n",
            "epoch: 10 |||   vloss type:   0.9346922039985657  validAcc type:   1.0 |||  vloss state 0.5679654479026794  validAcc state:  1.0  \n",
            "epoch: 10 |||   vloss type:   0.9452911615371704  validAcc type:   0.984375 |||  vloss state 0.5731115937232971  validAcc state:  0.984375  \n",
            "epoch: 10 |||   vloss type:   0.934381365776062  validAcc type:   0.984375 |||  vloss state 0.5719599723815918  validAcc state:  0.984375  \n",
            "epoch: 10 |||   vloss type:   0.9170187711715698  validAcc type:   1.0 |||  vloss state 0.5826153755187988  validAcc state:  1.0  \n",
            "epoch: 10 |||   vloss type:   0.9196933507919312  validAcc type:   1.0 |||  vloss state 0.5740122199058533  validAcc state:  1.0  \n",
            "epoch: 10 |||   vloss type:   0.9212814569473267  validAcc type:   1.0 |||  vloss state 0.5738726854324341  validAcc state:  1.0  \n",
            "Time:     1700.4735569953918\n",
            "epoch: 11 0 |||   loss type:   0.9165271520614624  trainAcc type:   1.0 |||  loss state 0.5618312954902649  trainAcc state:  1.0  \n",
            "epoch: 11 5 |||   loss type:   0.9208292961120605  trainAcc type:   1.0 |||  loss state 0.5780805945396423  trainAcc state:  0.984375  \n",
            "epoch: 11 10 |||   loss type:   0.9227784872055054  trainAcc type:   1.0 |||  loss state 0.568888247013092  trainAcc state:  0.984375  \n",
            "epoch: 11 15 |||   loss type:   0.9223741292953491  trainAcc type:   1.0 |||  loss state 0.5655871629714966  trainAcc state:  1.0  \n",
            "epoch: 11 20 |||   loss type:   0.924205482006073  trainAcc type:   1.0 |||  loss state 0.5735061168670654  trainAcc state:  0.984375  \n",
            "epoch: 11 25 |||   loss type:   0.9219452142715454  trainAcc type:   1.0 |||  loss state 0.5730020403862  trainAcc state:  1.0  \n",
            "epoch: 11 30 |||   loss type:   0.9304627180099487  trainAcc type:   1.0 |||  loss state 0.5843871235847473  trainAcc state:  0.96875  \n",
            "epoch: 11 35 |||   loss type:   0.9294202923774719  trainAcc type:   0.984375 |||  loss state 0.5785921216011047  trainAcc state:  0.984375  \n",
            "epoch: 11 40 |||   loss type:   0.9187283515930176  trainAcc type:   0.984375 |||  loss state 0.5736356377601624  trainAcc state:  0.984375  \n",
            "epoch: 11 45 |||   loss type:   0.9200789928436279  trainAcc type:   1.0 |||  loss state 0.5636171102523804  trainAcc state:  1.0  \n",
            "epoch: 11 50 |||   loss type:   0.9212263226509094  trainAcc type:   1.0 |||  loss state 0.5643550157546997  trainAcc state:  1.0  \n",
            "epoch: 11 55 |||   loss type:   0.9254835844039917  trainAcc type:   1.0 |||  loss state 0.5752053260803223  trainAcc state:  0.984375  \n",
            "epoch: 11 60 |||   loss type:   0.9284005165100098  trainAcc type:   1.0 |||  loss state 0.5737383365631104  trainAcc state:  0.984375  \n",
            "epoch: 11 65 |||   loss type:   0.9281873106956482  trainAcc type:   1.0 |||  loss state 0.5848878026008606  trainAcc state:  0.984375  \n",
            "epoch: 11 70 |||   loss type:   0.9295568466186523  trainAcc type:   0.984375 |||  loss state 0.5768282413482666  trainAcc state:  0.96875  \n",
            "epoch: 11 75 |||   loss type:   0.9176011681556702  trainAcc type:   1.0 |||  loss state 0.5715068578720093  trainAcc state:  0.984375  \n",
            "epoch: 11 80 |||   loss type:   0.9217372536659241  trainAcc type:   1.0 |||  loss state 0.5642402768135071  trainAcc state:  1.0  \n",
            "epoch: 11 85 |||   loss type:   0.9193292260169983  trainAcc type:   1.0 |||  loss state 0.5665574669837952  trainAcc state:  1.0  \n",
            "epoch: 11 90 |||   loss type:   0.9196193218231201  trainAcc type:   1.0 |||  loss state 0.5583418607711792  trainAcc state:  1.0  \n",
            "epoch: 11 95 |||   loss type:   0.9285268783569336  trainAcc type:   0.984375 |||  loss state 0.5683208703994751  trainAcc state:  1.0  \n",
            "epoch: 11 100 |||   loss type:   0.915317952632904  trainAcc type:   1.0 |||  loss state 0.5860357284545898  trainAcc state:  0.96875  \n",
            "epoch: 11 105 |||   loss type:   0.9241371154785156  trainAcc type:   0.984375 |||  loss state 0.5663413405418396  trainAcc state:  1.0  \n",
            "epoch: 11 110 |||   loss type:   0.9357818961143494  trainAcc type:   1.0 |||  loss state 0.5683139562606812  trainAcc state:  0.984375  \n",
            "epoch: 11 115 |||   loss type:   0.9326469898223877  trainAcc type:   0.984375 |||  loss state 0.5659298896789551  trainAcc state:  1.0  \n",
            "epoch: 11 120 |||   loss type:   0.9292300343513489  trainAcc type:   1.0 |||  loss state 0.5788536667823792  trainAcc state:  0.96875  \n",
            "epoch: 11 125 |||   loss type:   0.9136753678321838  trainAcc type:   1.0 |||  loss state 0.5945760011672974  trainAcc state:  0.953125  \n",
            "epoch: 11 130 |||   loss type:   0.916934609413147  trainAcc type:   0.984375 |||  loss state 0.5569857954978943  trainAcc state:  1.0  \n",
            "epoch: 11 135 |||   loss type:   0.931656539440155  trainAcc type:   0.984375 |||  loss state 0.5673165917396545  trainAcc state:  1.0  \n",
            "epoch: 11 140 |||   loss type:   0.9303088188171387  trainAcc type:   1.0 |||  loss state 0.573965311050415  trainAcc state:  1.0  \n",
            "epoch: 11 145 |||   loss type:   0.9238723516464233  trainAcc type:   1.0 |||  loss state 0.565552294254303  trainAcc state:  1.0  \n",
            "epoch: 11 |||   vloss type:   0.9333305358886719  validAcc type:   0.984375 |||  vloss state 0.5969348549842834  validAcc state:  0.953125  \n",
            "epoch: 11 |||   vloss type:   0.9272368550300598  validAcc type:   1.0 |||  vloss state 0.5704213380813599  validAcc state:  1.0  \n",
            "epoch: 11 |||   vloss type:   0.9334116578102112  validAcc type:   1.0 |||  vloss state 0.5664259791374207  validAcc state:  1.0  \n",
            "epoch: 11 |||   vloss type:   0.9429450035095215  validAcc type:   0.984375 |||  vloss state 0.5703085064888  validAcc state:  0.984375  \n",
            "epoch: 11 |||   vloss type:   0.9329741597175598  validAcc type:   0.984375 |||  vloss state 0.5709717869758606  validAcc state:  1.0  \n",
            "epoch: 11 |||   vloss type:   0.9162716269493103  validAcc type:   1.0 |||  vloss state 0.5799529552459717  validAcc state:  0.984375  \n",
            "epoch: 11 |||   vloss type:   0.9204002618789673  validAcc type:   1.0 |||  vloss state 0.5688976645469666  validAcc state:  1.0  \n",
            "epoch: 11 |||   vloss type:   0.9203518629074097  validAcc type:   1.0 |||  vloss state 0.5693177580833435  validAcc state:  1.0  \n",
            "Time:     1871.8641645908356\n",
            "epoch: 12 0 |||   loss type:   0.926445484161377  trainAcc type:   1.0 |||  loss state 0.5826194286346436  trainAcc state:  0.984375  \n",
            "epoch: 12 5 |||   loss type:   0.9310455322265625  trainAcc type:   1.0 |||  loss state 0.5753234624862671  trainAcc state:  1.0  \n",
            "epoch: 12 10 |||   loss type:   0.9211943745613098  trainAcc type:   1.0 |||  loss state 0.5605719089508057  trainAcc state:  1.0  \n",
            "epoch: 12 15 |||   loss type:   0.9226904511451721  trainAcc type:   0.984375 |||  loss state 0.5604939460754395  trainAcc state:  1.0  \n",
            "epoch: 12 20 |||   loss type:   0.9273340702056885  trainAcc type:   1.0 |||  loss state 0.5679640769958496  trainAcc state:  1.0  \n",
            "epoch: 12 25 |||   loss type:   0.9168221950531006  trainAcc type:   1.0 |||  loss state 0.5696151852607727  trainAcc state:  1.0  \n",
            "epoch: 12 30 |||   loss type:   0.9274776577949524  trainAcc type:   1.0 |||  loss state 0.57065749168396  trainAcc state:  1.0  \n",
            "epoch: 12 35 |||   loss type:   0.9200340509414673  trainAcc type:   0.984375 |||  loss state 0.564760148525238  trainAcc state:  1.0  \n",
            "epoch: 12 40 |||   loss type:   0.9140281677246094  trainAcc type:   1.0 |||  loss state 0.569882869720459  trainAcc state:  0.984375  \n",
            "epoch: 12 45 |||   loss type:   0.9201748371124268  trainAcc type:   1.0 |||  loss state 0.5798205733299255  trainAcc state:  0.984375  \n",
            "epoch: 12 50 |||   loss type:   0.9220367074012756  trainAcc type:   1.0 |||  loss state 0.5738419890403748  trainAcc state:  0.96875  \n",
            "epoch: 12 55 |||   loss type:   0.9243596792221069  trainAcc type:   1.0 |||  loss state 0.5677852630615234  trainAcc state:  1.0  \n",
            "epoch: 12 60 |||   loss type:   0.9242265224456787  trainAcc type:   1.0 |||  loss state 0.5870274901390076  trainAcc state:  0.984375  \n",
            "epoch: 12 65 |||   loss type:   0.9107604622840881  trainAcc type:   1.0 |||  loss state 0.5678367018699646  trainAcc state:  0.984375  \n",
            "epoch: 12 70 |||   loss type:   0.9172487258911133  trainAcc type:   1.0 |||  loss state 0.5597262382507324  trainAcc state:  1.0  \n",
            "epoch: 12 75 |||   loss type:   0.9143334627151489  trainAcc type:   1.0 |||  loss state 0.5669286847114563  trainAcc state:  1.0  \n",
            "epoch: 12 80 |||   loss type:   0.9100832939147949  trainAcc type:   1.0 |||  loss state 0.557066023349762  trainAcc state:  1.0  \n",
            "epoch: 12 85 |||   loss type:   0.9221400022506714  trainAcc type:   1.0 |||  loss state 0.5928419232368469  trainAcc state:  0.984375  \n",
            "epoch: 12 90 |||   loss type:   0.9141561388969421  trainAcc type:   1.0 |||  loss state 0.565261960029602  trainAcc state:  1.0  \n",
            "epoch: 12 95 |||   loss type:   0.9280105829238892  trainAcc type:   1.0 |||  loss state 0.5628615617752075  trainAcc state:  1.0  \n",
            "epoch: 12 100 |||   loss type:   0.9195919036865234  trainAcc type:   1.0 |||  loss state 0.5612858533859253  trainAcc state:  1.0  \n",
            "epoch: 12 105 |||   loss type:   0.9163708090782166  trainAcc type:   1.0 |||  loss state 0.5679029226303101  trainAcc state:  1.0  \n",
            "epoch: 12 110 |||   loss type:   0.933701753616333  trainAcc type:   1.0 |||  loss state 0.565944254398346  trainAcc state:  1.0  \n",
            "epoch: 12 115 |||   loss type:   0.9231187701225281  trainAcc type:   1.0 |||  loss state 0.5665396451950073  trainAcc state:  1.0  \n",
            "epoch: 12 120 |||   loss type:   0.9211443066596985  trainAcc type:   0.984375 |||  loss state 0.5640121698379517  trainAcc state:  0.984375  \n",
            "epoch: 12 125 |||   loss type:   0.920121967792511  trainAcc type:   1.0 |||  loss state 0.565906822681427  trainAcc state:  1.0  \n",
            "epoch: 12 130 |||   loss type:   0.917504608631134  trainAcc type:   1.0 |||  loss state 0.5670066475868225  trainAcc state:  0.984375  \n",
            "epoch: 12 135 |||   loss type:   0.9202741980552673  trainAcc type:   1.0 |||  loss state 0.5582696199417114  trainAcc state:  1.0  \n",
            "epoch: 12 140 |||   loss type:   0.9156351089477539  trainAcc type:   1.0 |||  loss state 0.572084367275238  trainAcc state:  0.984375  \n",
            "epoch: 12 145 |||   loss type:   0.9342073202133179  trainAcc type:   0.96875 |||  loss state 0.5649885535240173  trainAcc state:  1.0  \n",
            "epoch: 12 |||   vloss type:   0.931303083896637  validAcc type:   0.984375 |||  vloss state 0.5926036238670349  validAcc state:  0.953125  \n",
            "epoch: 12 |||   vloss type:   0.9236753582954407  validAcc type:   1.0 |||  vloss state 0.5689879655838013  validAcc state:  1.0  \n",
            "epoch: 12 |||   vloss type:   0.9324495792388916  validAcc type:   1.0 |||  vloss state 0.5660900473594666  validAcc state:  1.0  \n",
            "epoch: 12 |||   vloss type:   0.9394407868385315  validAcc type:   0.984375 |||  vloss state 0.5708692073822021  validAcc state:  0.984375  \n",
            "epoch: 12 |||   vloss type:   0.9297122359275818  validAcc type:   0.984375 |||  vloss state 0.5694878101348877  validAcc state:  1.0  \n",
            "epoch: 12 |||   vloss type:   0.914447546005249  validAcc type:   1.0 |||  vloss state 0.5774982571601868  validAcc state:  0.984375  \n",
            "epoch: 12 |||   vloss type:   0.9173170924186707  validAcc type:   1.0 |||  vloss state 0.5686941146850586  validAcc state:  1.0  \n",
            "epoch: 12 |||   vloss type:   0.9176125526428223  validAcc type:   1.0 |||  vloss state 0.5701937079429626  validAcc state:  1.0  \n",
            "Time:     2043.9465563297272\n",
            "epoch: 13 0 |||   loss type:   0.9196682572364807  trainAcc type:   1.0 |||  loss state 0.5549241900444031  trainAcc state:  1.0  \n",
            "epoch: 13 5 |||   loss type:   0.9245654344558716  trainAcc type:   0.984375 |||  loss state 0.5764127373695374  trainAcc state:  0.984375  \n",
            "epoch: 13 10 |||   loss type:   0.926819920539856  trainAcc type:   1.0 |||  loss state 0.5682334899902344  trainAcc state:  1.0  \n",
            "epoch: 13 15 |||   loss type:   0.9140200018882751  trainAcc type:   1.0 |||  loss state 0.5766512751579285  trainAcc state:  0.984375  \n",
            "epoch: 13 20 |||   loss type:   0.9261239171028137  trainAcc type:   1.0 |||  loss state 0.5735804438591003  trainAcc state:  0.984375  \n",
            "epoch: 13 25 |||   loss type:   0.9300441145896912  trainAcc type:   0.984375 |||  loss state 0.561988115310669  trainAcc state:  1.0  \n",
            "epoch: 13 30 |||   loss type:   0.9229474663734436  trainAcc type:   1.0 |||  loss state 0.5596396327018738  trainAcc state:  1.0  \n",
            "epoch: 13 35 |||   loss type:   0.9200617671012878  trainAcc type:   0.984375 |||  loss state 0.5804241299629211  trainAcc state:  0.984375  \n",
            "epoch: 13 40 |||   loss type:   0.9188973903656006  trainAcc type:   1.0 |||  loss state 0.5709484815597534  trainAcc state:  0.984375  \n",
            "epoch: 13 45 |||   loss type:   0.9142229557037354  trainAcc type:   1.0 |||  loss state 0.5665485858917236  trainAcc state:  1.0  \n",
            "epoch: 13 50 |||   loss type:   0.9160412549972534  trainAcc type:   1.0 |||  loss state 0.5811572670936584  trainAcc state:  0.984375  \n",
            "epoch: 13 55 |||   loss type:   0.921027660369873  trainAcc type:   1.0 |||  loss state 0.5575019717216492  trainAcc state:  1.0  \n",
            "epoch: 13 60 |||   loss type:   0.9215129613876343  trainAcc type:   1.0 |||  loss state 0.576595664024353  trainAcc state:  0.984375  \n",
            "epoch: 13 65 |||   loss type:   0.9159088730812073  trainAcc type:   0.984375 |||  loss state 0.5811704993247986  trainAcc state:  0.96875  \n",
            "epoch: 13 70 |||   loss type:   0.9261581301689148  trainAcc type:   1.0 |||  loss state 0.5752536654472351  trainAcc state:  0.984375  \n",
            "epoch: 13 75 |||   loss type:   0.9163053035736084  trainAcc type:   1.0 |||  loss state 0.5755875110626221  trainAcc state:  0.984375  \n",
            "epoch: 13 80 |||   loss type:   0.9117465615272522  trainAcc type:   1.0 |||  loss state 0.5607439875602722  trainAcc state:  1.0  \n",
            "epoch: 13 85 |||   loss type:   0.9204359650611877  trainAcc type:   1.0 |||  loss state 0.5654418468475342  trainAcc state:  1.0  \n",
            "epoch: 13 90 |||   loss type:   0.9212031364440918  trainAcc type:   1.0 |||  loss state 0.5686091780662537  trainAcc state:  1.0  \n",
            "epoch: 13 95 |||   loss type:   0.9166594743728638  trainAcc type:   1.0 |||  loss state 0.5740058422088623  trainAcc state:  0.984375  \n",
            "epoch: 13 100 |||   loss type:   0.919592559337616  trainAcc type:   0.984375 |||  loss state 0.5686333179473877  trainAcc state:  1.0  \n",
            "epoch: 13 105 |||   loss type:   0.9229196310043335  trainAcc type:   1.0 |||  loss state 0.5710905194282532  trainAcc state:  1.0  \n",
            "epoch: 13 110 |||   loss type:   0.9101829528808594  trainAcc type:   1.0 |||  loss state 0.5594974756240845  trainAcc state:  1.0  \n",
            "epoch: 13 115 |||   loss type:   0.9168825149536133  trainAcc type:   1.0 |||  loss state 0.5714670419692993  trainAcc state:  0.984375  \n",
            "epoch: 13 120 |||   loss type:   0.9158148169517517  trainAcc type:   1.0 |||  loss state 0.5622713565826416  trainAcc state:  1.0  \n",
            "epoch: 13 125 |||   loss type:   0.9197470545768738  trainAcc type:   1.0 |||  loss state 0.5632753968238831  trainAcc state:  1.0  \n",
            "epoch: 13 130 |||   loss type:   0.9253354072570801  trainAcc type:   0.96875 |||  loss state 0.563157320022583  trainAcc state:  1.0  \n",
            "epoch: 13 135 |||   loss type:   0.9299905896186829  trainAcc type:   0.96875 |||  loss state 0.5664146542549133  trainAcc state:  1.0  \n",
            "epoch: 13 140 |||   loss type:   0.9254168272018433  trainAcc type:   1.0 |||  loss state 0.5621762275695801  trainAcc state:  1.0  \n",
            "epoch: 13 145 |||   loss type:   0.9129841327667236  trainAcc type:   1.0 |||  loss state 0.5791402459144592  trainAcc state:  0.984375  \n",
            "epoch: 13 |||   vloss type:   0.9291046857833862  validAcc type:   0.984375 |||  vloss state 0.594084620475769  validAcc state:  0.953125  \n",
            "epoch: 13 |||   vloss type:   0.9212695956230164  validAcc type:   1.0 |||  vloss state 0.566755473613739  validAcc state:  1.0  \n",
            "epoch: 13 |||   vloss type:   0.9316744804382324  validAcc type:   1.0 |||  vloss state 0.5638562440872192  validAcc state:  1.0  \n",
            "epoch: 13 |||   vloss type:   0.9372459053993225  validAcc type:   0.984375 |||  vloss state 0.5703379511833191  validAcc state:  0.984375  \n",
            "epoch: 13 |||   vloss type:   0.9267391562461853  validAcc type:   0.984375 |||  vloss state 0.5675891637802124  validAcc state:  1.0  \n",
            "epoch: 13 |||   vloss type:   0.9128981828689575  validAcc type:   1.0 |||  vloss state 0.5734961032867432  validAcc state:  1.0  \n",
            "epoch: 13 |||   vloss type:   0.9158862829208374  validAcc type:   1.0 |||  vloss state 0.565887451171875  validAcc state:  1.0  \n",
            "epoch: 13 |||   vloss type:   0.9154332280158997  validAcc type:   1.0 |||  vloss state 0.5661724209785461  validAcc state:  1.0  \n",
            "Time:     2213.032530069351\n",
            "epoch: 14 0 |||   loss type:   0.9156344532966614  trainAcc type:   1.0 |||  loss state 0.5565529465675354  trainAcc state:  1.0  \n",
            "epoch: 14 5 |||   loss type:   0.910259485244751  trainAcc type:   1.0 |||  loss state 0.5562774538993835  trainAcc state:  1.0  \n",
            "epoch: 14 10 |||   loss type:   0.9169208407402039  trainAcc type:   1.0 |||  loss state 0.5640766620635986  trainAcc state:  1.0  \n",
            "epoch: 14 15 |||   loss type:   0.9209736585617065  trainAcc type:   1.0 |||  loss state 0.565553605556488  trainAcc state:  0.984375  \n",
            "epoch: 14 20 |||   loss type:   0.9178241491317749  trainAcc type:   1.0 |||  loss state 0.5839154720306396  trainAcc state:  0.984375  \n",
            "epoch: 14 25 |||   loss type:   0.9200207591056824  trainAcc type:   1.0 |||  loss state 0.5773011445999146  trainAcc state:  0.984375  \n",
            "epoch: 14 30 |||   loss type:   0.9101292490959167  trainAcc type:   1.0 |||  loss state 0.555514931678772  trainAcc state:  1.0  \n",
            "epoch: 14 35 |||   loss type:   0.9152552485466003  trainAcc type:   1.0 |||  loss state 0.5631518959999084  trainAcc state:  1.0  \n",
            "epoch: 14 40 |||   loss type:   0.9259610772132874  trainAcc type:   1.0 |||  loss state 0.5621612668037415  trainAcc state:  1.0  \n",
            "epoch: 14 45 |||   loss type:   0.92593914270401  trainAcc type:   0.984375 |||  loss state 0.5617256164550781  trainAcc state:  1.0  \n",
            "epoch: 14 50 |||   loss type:   0.9220888614654541  trainAcc type:   1.0 |||  loss state 0.5716245770454407  trainAcc state:  0.984375  \n",
            "epoch: 14 55 |||   loss type:   0.9140371084213257  trainAcc type:   1.0 |||  loss state 0.5682730674743652  trainAcc state:  0.984375  \n",
            "epoch: 14 60 |||   loss type:   0.9156970977783203  trainAcc type:   1.0 |||  loss state 0.5709424018859863  trainAcc state:  0.984375  \n",
            "epoch: 14 65 |||   loss type:   0.9156438708305359  trainAcc type:   1.0 |||  loss state 0.5636342167854309  trainAcc state:  1.0  \n",
            "epoch: 14 70 |||   loss type:   0.9215927720069885  trainAcc type:   1.0 |||  loss state 0.5592955350875854  trainAcc state:  1.0  \n",
            "epoch: 14 75 |||   loss type:   0.9170251488685608  trainAcc type:   1.0 |||  loss state 0.5605736970901489  trainAcc state:  1.0  \n",
            "epoch: 14 80 |||   loss type:   0.9206211566925049  trainAcc type:   1.0 |||  loss state 0.5702944397926331  trainAcc state:  0.984375  \n",
            "epoch: 14 85 |||   loss type:   0.9116401076316833  trainAcc type:   1.0 |||  loss state 0.5624563097953796  trainAcc state:  1.0  \n",
            "epoch: 14 90 |||   loss type:   0.9216850399971008  trainAcc type:   1.0 |||  loss state 0.5637215375900269  trainAcc state:  1.0  \n",
            "epoch: 14 95 |||   loss type:   0.9149929285049438  trainAcc type:   1.0 |||  loss state 0.559630274772644  trainAcc state:  1.0  \n",
            "epoch: 14 100 |||   loss type:   0.9147095680236816  trainAcc type:   1.0 |||  loss state 0.5546874403953552  trainAcc state:  1.0  \n",
            "epoch: 14 105 |||   loss type:   0.9225876331329346  trainAcc type:   0.984375 |||  loss state 0.5788646340370178  trainAcc state:  0.984375  \n",
            "epoch: 14 110 |||   loss type:   0.9262218475341797  trainAcc type:   0.984375 |||  loss state 0.563129186630249  trainAcc state:  1.0  \n",
            "epoch: 14 115 |||   loss type:   0.9140161275863647  trainAcc type:   1.0 |||  loss state 0.5649505853652954  trainAcc state:  1.0  \n",
            "epoch: 14 120 |||   loss type:   0.9215605854988098  trainAcc type:   0.984375 |||  loss state 0.5600766539573669  trainAcc state:  1.0  \n",
            "epoch: 14 125 |||   loss type:   0.9183515906333923  trainAcc type:   1.0 |||  loss state 0.5717739462852478  trainAcc state:  0.984375  \n",
            "epoch: 14 130 |||   loss type:   0.926680862903595  trainAcc type:   1.0 |||  loss state 0.566180408000946  trainAcc state:  1.0  \n",
            "epoch: 14 135 |||   loss type:   0.9135167002677917  trainAcc type:   1.0 |||  loss state 0.5578839182853699  trainAcc state:  1.0  \n",
            "epoch: 14 140 |||   loss type:   0.9147387146949768  trainAcc type:   1.0 |||  loss state 0.5605967044830322  trainAcc state:  1.0  \n",
            "epoch: 14 145 |||   loss type:   0.9191769361495972  trainAcc type:   1.0 |||  loss state 0.5645462870597839  trainAcc state:  0.984375  \n",
            "epoch: 14 |||   vloss type:   0.9298043251037598  validAcc type:   0.984375 |||  vloss state 0.5947622060775757  validAcc state:  0.953125  \n",
            "epoch: 14 |||   vloss type:   0.9207377433776855  validAcc type:   1.0 |||  vloss state 0.5648839473724365  validAcc state:  1.0  \n",
            "epoch: 14 |||   vloss type:   0.9316264390945435  validAcc type:   1.0 |||  vloss state 0.5645149946212769  validAcc state:  1.0  \n",
            "epoch: 14 |||   vloss type:   0.9366617202758789  validAcc type:   0.984375 |||  vloss state 0.5692701935768127  validAcc state:  0.984375  \n",
            "epoch: 14 |||   vloss type:   0.9267985224723816  validAcc type:   0.984375 |||  vloss state 0.5676170587539673  validAcc state:  1.0  \n",
            "epoch: 14 |||   vloss type:   0.9129526019096375  validAcc type:   1.0 |||  vloss state 0.5731323957443237  validAcc state:  1.0  \n",
            "epoch: 14 |||   vloss type:   0.9158493280410767  validAcc type:   1.0 |||  vloss state 0.5647777318954468  validAcc state:  1.0  \n",
            "epoch: 14 |||   vloss type:   0.9160119891166687  validAcc type:   1.0 |||  vloss state 0.5663245916366577  validAcc state:  1.0  \n",
            "Time:     2377.325464487076\n",
            "epoch: 15 0 |||   loss type:   0.9110642075538635  trainAcc type:   1.0 |||  loss state 0.570369303226471  trainAcc state:  0.984375  \n",
            "epoch: 15 5 |||   loss type:   0.9152939915657043  trainAcc type:   1.0 |||  loss state 0.5617313385009766  trainAcc state:  1.0  \n",
            "epoch: 15 10 |||   loss type:   0.9170288443565369  trainAcc type:   1.0 |||  loss state 0.5630306005477905  trainAcc state:  1.0  \n",
            "epoch: 15 15 |||   loss type:   0.9185912609100342  trainAcc type:   1.0 |||  loss state 0.5614950656890869  trainAcc state:  1.0  \n",
            "epoch: 15 20 |||   loss type:   0.9133631587028503  trainAcc type:   1.0 |||  loss state 0.5658388733863831  trainAcc state:  1.0  \n",
            "epoch: 15 25 |||   loss type:   0.916621744632721  trainAcc type:   1.0 |||  loss state 0.5588950514793396  trainAcc state:  1.0  \n",
            "epoch: 15 30 |||   loss type:   0.9197890162467957  trainAcc type:   1.0 |||  loss state 0.5648728013038635  trainAcc state:  1.0  \n",
            "epoch: 15 35 |||   loss type:   0.9220831990242004  trainAcc type:   0.984375 |||  loss state 0.5590980052947998  trainAcc state:  1.0  \n",
            "epoch: 15 40 |||   loss type:   0.9206731915473938  trainAcc type:   1.0 |||  loss state 0.5635813474655151  trainAcc state:  1.0  \n",
            "epoch: 15 45 |||   loss type:   0.9167976975440979  trainAcc type:   1.0 |||  loss state 0.5601785182952881  trainAcc state:  1.0  \n",
            "epoch: 15 50 |||   loss type:   0.9125198125839233  trainAcc type:   1.0 |||  loss state 0.5570498108863831  trainAcc state:  1.0  \n",
            "epoch: 15 55 |||   loss type:   0.911668062210083  trainAcc type:   1.0 |||  loss state 0.5714558362960815  trainAcc state:  1.0  \n",
            "epoch: 15 60 |||   loss type:   0.9146509766578674  trainAcc type:   1.0 |||  loss state 0.5654038190841675  trainAcc state:  0.984375  \n",
            "epoch: 15 65 |||   loss type:   0.9160811901092529  trainAcc type:   1.0 |||  loss state 0.5778578519821167  trainAcc state:  0.984375  \n",
            "epoch: 15 70 |||   loss type:   0.9154960513114929  trainAcc type:   1.0 |||  loss state 0.6087883114814758  trainAcc state:  0.953125  \n",
            "epoch: 15 75 |||   loss type:   0.9208827018737793  trainAcc type:   1.0 |||  loss state 0.5768210291862488  trainAcc state:  0.984375  \n",
            "epoch: 15 80 |||   loss type:   0.9184709787368774  trainAcc type:   1.0 |||  loss state 0.5626748204231262  trainAcc state:  1.0  \n",
            "epoch: 15 85 |||   loss type:   0.9193070530891418  trainAcc type:   1.0 |||  loss state 0.5565766096115112  trainAcc state:  1.0  \n",
            "epoch: 15 90 |||   loss type:   0.9294299483299255  trainAcc type:   0.984375 |||  loss state 0.5606231093406677  trainAcc state:  1.0  \n",
            "epoch: 15 95 |||   loss type:   0.9142677187919617  trainAcc type:   1.0 |||  loss state 0.5638978481292725  trainAcc state:  1.0  \n",
            "epoch: 15 100 |||   loss type:   0.922211229801178  trainAcc type:   0.984375 |||  loss state 0.5773064494132996  trainAcc state:  0.984375  \n",
            "epoch: 15 105 |||   loss type:   0.9180625081062317  trainAcc type:   0.984375 |||  loss state 0.577238917350769  trainAcc state:  0.984375  \n",
            "epoch: 15 110 |||   loss type:   0.9116424918174744  trainAcc type:   1.0 |||  loss state 0.5706816911697388  trainAcc state:  0.984375  \n",
            "epoch: 15 115 |||   loss type:   0.9153426289558411  trainAcc type:   1.0 |||  loss state 0.5594226121902466  trainAcc state:  1.0  \n",
            "epoch: 15 120 |||   loss type:   0.9163414835929871  trainAcc type:   1.0 |||  loss state 0.5604377388954163  trainAcc state:  1.0  \n",
            "epoch: 15 125 |||   loss type:   0.9157086610794067  trainAcc type:   1.0 |||  loss state 0.5601887702941895  trainAcc state:  1.0  \n",
            "epoch: 15 130 |||   loss type:   0.915899395942688  trainAcc type:   1.0 |||  loss state 0.5762806534767151  trainAcc state:  0.984375  \n",
            "epoch: 15 135 |||   loss type:   0.9232236742973328  trainAcc type:   1.0 |||  loss state 0.5622063875198364  trainAcc state:  1.0  \n",
            "epoch: 15 140 |||   loss type:   0.9194372892379761  trainAcc type:   1.0 |||  loss state 0.5731625556945801  trainAcc state:  0.984375  \n",
            "epoch: 15 145 |||   loss type:   0.9182352423667908  trainAcc type:   1.0 |||  loss state 0.5601435303688049  trainAcc state:  1.0  \n",
            "epoch: 15 |||   vloss type:   0.9297618865966797  validAcc type:   0.984375 |||  vloss state 0.5931050181388855  validAcc state:  0.953125  \n",
            "epoch: 15 |||   vloss type:   0.9211767911911011  validAcc type:   1.0 |||  vloss state 0.5661805272102356  validAcc state:  1.0  \n",
            "epoch: 15 |||   vloss type:   0.9308908581733704  validAcc type:   1.0 |||  vloss state 0.5648924112319946  validAcc state:  1.0  \n",
            "epoch: 15 |||   vloss type:   0.9375597834587097  validAcc type:   0.984375 |||  vloss state 0.5688976645469666  validAcc state:  0.984375  \n",
            "epoch: 15 |||   vloss type:   0.9273802042007446  validAcc type:   0.984375 |||  vloss state 0.5674216747283936  validAcc state:  1.0  \n",
            "epoch: 15 |||   vloss type:   0.9129630327224731  validAcc type:   1.0 |||  vloss state 0.5732748508453369  validAcc state:  0.984375  \n",
            "epoch: 15 |||   vloss type:   0.9152939915657043  validAcc type:   1.0 |||  vloss state 0.5660293102264404  validAcc state:  1.0  \n",
            "epoch: 15 |||   vloss type:   0.9159711003303528  validAcc type:   1.0 |||  vloss state 0.567399263381958  validAcc state:  1.0  \n",
            "Time:     2538.8480949401855\n",
            "epoch: 16 0 |||   loss type:   0.9193800091743469  trainAcc type:   1.0 |||  loss state 0.5612380504608154  trainAcc state:  1.0  \n",
            "epoch: 16 5 |||   loss type:   0.9142957329750061  trainAcc type:   1.0 |||  loss state 0.554645836353302  trainAcc state:  1.0  \n",
            "epoch: 16 10 |||   loss type:   0.9155083298683167  trainAcc type:   1.0 |||  loss state 0.5784536004066467  trainAcc state:  0.984375  \n",
            "epoch: 16 15 |||   loss type:   0.9223525524139404  trainAcc type:   1.0 |||  loss state 0.5762218832969666  trainAcc state:  0.984375  \n",
            "epoch: 16 20 |||   loss type:   0.9143698215484619  trainAcc type:   1.0 |||  loss state 0.5680758357048035  trainAcc state:  0.984375  \n",
            "epoch: 16 25 |||   loss type:   0.9210973381996155  trainAcc type:   1.0 |||  loss state 0.563129186630249  trainAcc state:  1.0  \n",
            "epoch: 16 30 |||   loss type:   0.9171583652496338  trainAcc type:   1.0 |||  loss state 0.5694706439971924  trainAcc state:  0.984375  \n",
            "epoch: 16 35 |||   loss type:   0.9174952507019043  trainAcc type:   1.0 |||  loss state 0.56864333152771  trainAcc state:  1.0  \n",
            "epoch: 16 40 |||   loss type:   0.9179527759552002  trainAcc type:   1.0 |||  loss state 0.5599017143249512  trainAcc state:  1.0  \n",
            "epoch: 16 45 |||   loss type:   0.9133180379867554  trainAcc type:   1.0 |||  loss state 0.5532135367393494  trainAcc state:  1.0  \n",
            "epoch: 16 50 |||   loss type:   0.9153339862823486  trainAcc type:   1.0 |||  loss state 0.5761246085166931  trainAcc state:  0.984375  \n",
            "epoch: 16 55 |||   loss type:   0.9072359204292297  trainAcc type:   1.0 |||  loss state 0.5569097995758057  trainAcc state:  1.0  \n",
            "epoch: 16 60 |||   loss type:   0.9190951585769653  trainAcc type:   1.0 |||  loss state 0.557896077632904  trainAcc state:  1.0  \n",
            "epoch: 16 65 |||   loss type:   0.9179078340530396  trainAcc type:   1.0 |||  loss state 0.565346360206604  trainAcc state:  0.984375  \n",
            "epoch: 16 70 |||   loss type:   0.9193934798240662  trainAcc type:   1.0 |||  loss state 0.5558906197547913  trainAcc state:  1.0  \n",
            "epoch: 16 75 |||   loss type:   0.9141533970832825  trainAcc type:   1.0 |||  loss state 0.5610445737838745  trainAcc state:  1.0  \n",
            "epoch: 16 80 |||   loss type:   0.9143072962760925  trainAcc type:   1.0 |||  loss state 0.5620958805084229  trainAcc state:  1.0  \n",
            "epoch: 16 85 |||   loss type:   0.9154583215713501  trainAcc type:   1.0 |||  loss state 0.5590856671333313  trainAcc state:  1.0  \n",
            "epoch: 16 90 |||   loss type:   0.9162679314613342  trainAcc type:   1.0 |||  loss state 0.5694642066955566  trainAcc state:  0.984375  \n",
            "epoch: 16 95 |||   loss type:   0.9252885580062866  trainAcc type:   0.984375 |||  loss state 0.5598472356796265  trainAcc state:  1.0  \n",
            "epoch: 16 100 |||   loss type:   0.9148889780044556  trainAcc type:   1.0 |||  loss state 0.5669158101081848  trainAcc state:  1.0  \n",
            "epoch: 16 105 |||   loss type:   0.9231464862823486  trainAcc type:   1.0 |||  loss state 0.5587010979652405  trainAcc state:  1.0  \n",
            "epoch: 16 110 |||   loss type:   0.9115933775901794  trainAcc type:   1.0 |||  loss state 0.5875788927078247  trainAcc state:  0.953125  \n",
            "epoch: 16 115 |||   loss type:   0.9138416647911072  trainAcc type:   1.0 |||  loss state 0.5594861507415771  trainAcc state:  1.0  \n",
            "epoch: 16 120 |||   loss type:   0.921587347984314  trainAcc type:   1.0 |||  loss state 0.5646316409111023  trainAcc state:  1.0  \n",
            "epoch: 16 125 |||   loss type:   0.9206599593162537  trainAcc type:   1.0 |||  loss state 0.569671630859375  trainAcc state:  1.0  \n",
            "epoch: 16 130 |||   loss type:   0.9151657223701477  trainAcc type:   1.0 |||  loss state 0.5941841006278992  trainAcc state:  0.953125  \n",
            "epoch: 16 135 |||   loss type:   0.9141619801521301  trainAcc type:   1.0 |||  loss state 0.5588505268096924  trainAcc state:  1.0  \n",
            "epoch: 16 140 |||   loss type:   0.9172767400741577  trainAcc type:   1.0 |||  loss state 0.5628073811531067  trainAcc state:  1.0  \n",
            "epoch: 16 145 |||   loss type:   0.9112836122512817  trainAcc type:   1.0 |||  loss state 0.5552963614463806  trainAcc state:  1.0  \n",
            "epoch: 16 |||   vloss type:   0.9280242919921875  validAcc type:   0.984375 |||  vloss state 0.591320276260376  validAcc state:  0.953125  \n",
            "epoch: 16 |||   vloss type:   0.919105589389801  validAcc type:   1.0 |||  vloss state 0.5646583437919617  validAcc state:  1.0  \n",
            "epoch: 16 |||   vloss type:   0.9290874004364014  validAcc type:   1.0 |||  vloss state 0.5627399682998657  validAcc state:  1.0  \n",
            "epoch: 16 |||   vloss type:   0.9334170818328857  validAcc type:   0.984375 |||  vloss state 0.5690484642982483  validAcc state:  0.984375  \n",
            "epoch: 16 |||   vloss type:   0.9250890016555786  validAcc type:   1.0 |||  vloss state 0.5673590302467346  validAcc state:  1.0  \n",
            "epoch: 16 |||   vloss type:   0.9122588038444519  validAcc type:   1.0 |||  vloss state 0.5724448561668396  validAcc state:  1.0  \n",
            "epoch: 16 |||   vloss type:   0.9149775505065918  validAcc type:   1.0 |||  vloss state 0.5643702149391174  validAcc state:  1.0  \n",
            "epoch: 16 |||   vloss type:   0.9149555563926697  validAcc type:   1.0 |||  vloss state 0.5648238062858582  validAcc state:  1.0  \n",
            "Time:     2701.274842262268\n",
            "epoch: 17 0 |||   loss type:   0.912980318069458  trainAcc type:   1.0 |||  loss state 0.5587338209152222  trainAcc state:  1.0  \n",
            "epoch: 17 5 |||   loss type:   0.9132077097892761  trainAcc type:   1.0 |||  loss state 0.5593513250350952  trainAcc state:  1.0  \n",
            "epoch: 17 10 |||   loss type:   0.9128081202507019  trainAcc type:   1.0 |||  loss state 0.5569358468055725  trainAcc state:  1.0  \n",
            "epoch: 17 15 |||   loss type:   0.9173034429550171  trainAcc type:   1.0 |||  loss state 0.5644105672836304  trainAcc state:  1.0  \n",
            "epoch: 17 20 |||   loss type:   0.9114854335784912  trainAcc type:   1.0 |||  loss state 0.5635884404182434  trainAcc state:  0.984375  \n",
            "epoch: 17 25 |||   loss type:   0.9105392694473267  trainAcc type:   1.0 |||  loss state 0.5674238204956055  trainAcc state:  0.984375  \n",
            "epoch: 17 30 |||   loss type:   0.90794837474823  trainAcc type:   1.0 |||  loss state 0.5655965209007263  trainAcc state:  1.0  \n",
            "epoch: 17 35 |||   loss type:   0.9196676015853882  trainAcc type:   1.0 |||  loss state 0.5570858716964722  trainAcc state:  1.0  \n",
            "epoch: 17 40 |||   loss type:   0.9171420335769653  trainAcc type:   1.0 |||  loss state 0.56239914894104  trainAcc state:  1.0  \n",
            "epoch: 17 45 |||   loss type:   0.9146122336387634  trainAcc type:   1.0 |||  loss state 0.5631911158561707  trainAcc state:  0.984375  \n",
            "epoch: 17 50 |||   loss type:   0.9102689623832703  trainAcc type:   1.0 |||  loss state 0.5687540769577026  trainAcc state:  0.984375  \n",
            "epoch: 17 55 |||   loss type:   0.9137213230133057  trainAcc type:   1.0 |||  loss state 0.5621122121810913  trainAcc state:  1.0  \n",
            "epoch: 17 60 |||   loss type:   0.9253859519958496  trainAcc type:   1.0 |||  loss state 0.5656399726867676  trainAcc state:  1.0  \n",
            "epoch: 17 65 |||   loss type:   0.9130019545555115  trainAcc type:   1.0 |||  loss state 0.5627666711807251  trainAcc state:  1.0  \n",
            "epoch: 17 70 |||   loss type:   0.9121189117431641  trainAcc type:   1.0 |||  loss state 0.5661126375198364  trainAcc state:  0.984375  \n",
            "epoch: 17 75 |||   loss type:   0.9173362851142883  trainAcc type:   1.0 |||  loss state 0.5918594598770142  trainAcc state:  0.953125  \n",
            "epoch: 17 80 |||   loss type:   0.9135537147521973  trainAcc type:   1.0 |||  loss state 0.5754023194313049  trainAcc state:  0.984375  \n",
            "epoch: 17 85 |||   loss type:   0.9168239831924438  trainAcc type:   1.0 |||  loss state 0.570328414440155  trainAcc state:  0.984375  \n",
            "epoch: 17 90 |||   loss type:   0.919482946395874  trainAcc type:   1.0 |||  loss state 0.5574358701705933  trainAcc state:  1.0  \n",
            "epoch: 17 95 |||   loss type:   0.9187890887260437  trainAcc type:   1.0 |||  loss state 0.5637955069541931  trainAcc state:  0.984375  \n",
            "epoch: 17 100 |||   loss type:   0.9161087274551392  trainAcc type:   1.0 |||  loss state 0.5552479028701782  trainAcc state:  1.0  \n",
            "epoch: 17 105 |||   loss type:   0.9136810302734375  trainAcc type:   1.0 |||  loss state 0.556374192237854  trainAcc state:  1.0  \n",
            "epoch: 17 110 |||   loss type:   0.9123023748397827  trainAcc type:   1.0 |||  loss state 0.5636067390441895  trainAcc state:  1.0  \n",
            "epoch: 17 115 |||   loss type:   0.9162541031837463  trainAcc type:   1.0 |||  loss state 0.5824599862098694  trainAcc state:  0.953125  \n",
            "epoch: 17 120 |||   loss type:   0.9106425046920776  trainAcc type:   1.0 |||  loss state 0.5595173835754395  trainAcc state:  1.0  \n",
            "epoch: 17 125 |||   loss type:   0.9203284978866577  trainAcc type:   1.0 |||  loss state 0.5692676901817322  trainAcc state:  0.984375  \n",
            "epoch: 17 130 |||   loss type:   0.9130693674087524  trainAcc type:   1.0 |||  loss state 0.56302809715271  trainAcc state:  1.0  \n",
            "epoch: 17 135 |||   loss type:   0.9171245098114014  trainAcc type:   1.0 |||  loss state 0.5796194076538086  trainAcc state:  0.984375  \n",
            "epoch: 17 140 |||   loss type:   0.9165633916854858  trainAcc type:   1.0 |||  loss state 0.5625717639923096  trainAcc state:  1.0  \n",
            "epoch: 17 145 |||   loss type:   0.9149903655052185  trainAcc type:   1.0 |||  loss state 0.5566204190254211  trainAcc state:  1.0  \n",
            "epoch: 17 |||   vloss type:   0.9262082576751709  validAcc type:   0.984375 |||  vloss state 0.5877148509025574  validAcc state:  0.953125  \n",
            "epoch: 17 |||   vloss type:   0.918603777885437  validAcc type:   1.0 |||  vloss state 0.564216673374176  validAcc state:  1.0  \n",
            "epoch: 17 |||   vloss type:   0.9306561350822449  validAcc type:   1.0 |||  vloss state 0.5634703040122986  validAcc state:  1.0  \n",
            "epoch: 17 |||   vloss type:   0.9326884746551514  validAcc type:   0.984375 |||  vloss state 0.5663769841194153  validAcc state:  0.984375  \n",
            "epoch: 17 |||   vloss type:   0.9247366189956665  validAcc type:   0.984375 |||  vloss state 0.5674232244491577  validAcc state:  1.0  \n",
            "epoch: 17 |||   vloss type:   0.9119709730148315  validAcc type:   1.0 |||  vloss state 0.5727196335792542  validAcc state:  0.984375  \n",
            "epoch: 17 |||   vloss type:   0.9160088896751404  validAcc type:   1.0 |||  vloss state 0.5631897449493408  validAcc state:  1.0  \n",
            "epoch: 17 |||   vloss type:   0.9146774411201477  validAcc type:   1.0 |||  vloss state 0.5643622279167175  validAcc state:  1.0  \n",
            "Time:     2866.08860707283\n",
            "epoch: 18 0 |||   loss type:   0.9153193831443787  trainAcc type:   1.0 |||  loss state 0.5672670006752014  trainAcc state:  0.984375  \n",
            "epoch: 18 5 |||   loss type:   0.9183551669120789  trainAcc type:   1.0 |||  loss state 0.5564443469047546  trainAcc state:  1.0  \n",
            "epoch: 18 10 |||   loss type:   0.9159886240959167  trainAcc type:   1.0 |||  loss state 0.5632180571556091  trainAcc state:  1.0  \n",
            "epoch: 18 15 |||   loss type:   0.9135239124298096  trainAcc type:   1.0 |||  loss state 0.5621150135993958  trainAcc state:  1.0  \n",
            "epoch: 18 20 |||   loss type:   0.9143297672271729  trainAcc type:   0.984375 |||  loss state 0.5613089203834534  trainAcc state:  1.0  \n",
            "epoch: 18 25 |||   loss type:   0.9133654832839966  trainAcc type:   1.0 |||  loss state 0.5597338080406189  trainAcc state:  1.0  \n",
            "epoch: 18 30 |||   loss type:   0.9143185615539551  trainAcc type:   1.0 |||  loss state 0.559583306312561  trainAcc state:  1.0  \n",
            "epoch: 18 35 |||   loss type:   0.9110046625137329  trainAcc type:   1.0 |||  loss state 0.5570051074028015  trainAcc state:  1.0  \n",
            "epoch: 18 40 |||   loss type:   0.9091848134994507  trainAcc type:   1.0 |||  loss state 0.5635727643966675  trainAcc state:  1.0  \n",
            "epoch: 18 45 |||   loss type:   0.9097254872322083  trainAcc type:   1.0 |||  loss state 0.5532177686691284  trainAcc state:  1.0  \n",
            "epoch: 18 50 |||   loss type:   0.910627543926239  trainAcc type:   1.0 |||  loss state 0.5582895278930664  trainAcc state:  1.0  \n",
            "epoch: 18 55 |||   loss type:   0.913623034954071  trainAcc type:   1.0 |||  loss state 0.5585062503814697  trainAcc state:  1.0  \n",
            "epoch: 18 60 |||   loss type:   0.9107396006584167  trainAcc type:   1.0 |||  loss state 0.5603217482566833  trainAcc state:  1.0  \n",
            "epoch: 18 65 |||   loss type:   0.9136035442352295  trainAcc type:   1.0 |||  loss state 0.5580127835273743  trainAcc state:  1.0  \n",
            "epoch: 18 70 |||   loss type:   0.91242516040802  trainAcc type:   1.0 |||  loss state 0.5657157897949219  trainAcc state:  1.0  \n",
            "epoch: 18 75 |||   loss type:   0.9212615489959717  trainAcc type:   1.0 |||  loss state 0.5587717890739441  trainAcc state:  1.0  \n",
            "epoch: 18 80 |||   loss type:   0.9137346148490906  trainAcc type:   1.0 |||  loss state 0.5681943297386169  trainAcc state:  0.984375  \n",
            "epoch: 18 85 |||   loss type:   0.917837917804718  trainAcc type:   1.0 |||  loss state 0.5588224530220032  trainAcc state:  1.0  \n",
            "epoch: 18 90 |||   loss type:   0.9175149202346802  trainAcc type:   1.0 |||  loss state 0.5699037313461304  trainAcc state:  0.984375  \n",
            "epoch: 18 95 |||   loss type:   0.9096755385398865  trainAcc type:   1.0 |||  loss state 0.5579214096069336  trainAcc state:  1.0  \n",
            "epoch: 18 100 |||   loss type:   0.9144755005836487  trainAcc type:   1.0 |||  loss state 0.5767577290534973  trainAcc state:  0.984375  \n",
            "epoch: 18 105 |||   loss type:   0.9154775142669678  trainAcc type:   1.0 |||  loss state 0.5576361417770386  trainAcc state:  1.0  \n",
            "epoch: 18 110 |||   loss type:   0.9132356643676758  trainAcc type:   1.0 |||  loss state 0.5592896938323975  trainAcc state:  1.0  \n",
            "epoch: 18 115 |||   loss type:   0.910376787185669  trainAcc type:   1.0 |||  loss state 0.5618811845779419  trainAcc state:  1.0  \n",
            "epoch: 18 120 |||   loss type:   0.9106383919715881  trainAcc type:   1.0 |||  loss state 0.5737059116363525  trainAcc state:  0.984375  \n",
            "epoch: 18 125 |||   loss type:   0.9109951257705688  trainAcc type:   1.0 |||  loss state 0.5587023496627808  trainAcc state:  1.0  \n",
            "epoch: 18 130 |||   loss type:   0.917631208896637  trainAcc type:   1.0 |||  loss state 0.5541597008705139  trainAcc state:  1.0  \n",
            "epoch: 18 135 |||   loss type:   0.9089073538780212  trainAcc type:   1.0 |||  loss state 0.5555346608161926  trainAcc state:  1.0  \n",
            "epoch: 18 140 |||   loss type:   0.9145815372467041  trainAcc type:   1.0 |||  loss state 0.5578263401985168  trainAcc state:  1.0  \n",
            "epoch: 18 145 |||   loss type:   0.9139785766601562  trainAcc type:   1.0 |||  loss state 0.5585154891014099  trainAcc state:  1.0  \n",
            "epoch: 18 |||   vloss type:   0.9261251091957092  validAcc type:   0.984375 |||  vloss state 0.5897431969642639  validAcc state:  0.953125  \n",
            "epoch: 18 |||   vloss type:   0.9170202016830444  validAcc type:   1.0 |||  vloss state 0.5628557205200195  validAcc state:  1.0  \n",
            "epoch: 18 |||   vloss type:   0.9290691614151001  validAcc type:   1.0 |||  vloss state 0.5621472001075745  validAcc state:  1.0  \n",
            "epoch: 18 |||   vloss type:   0.9315848350524902  validAcc type:   0.984375 |||  vloss state 0.5683737397193909  validAcc state:  0.984375  \n",
            "epoch: 18 |||   vloss type:   0.9236237406730652  validAcc type:   1.0 |||  vloss state 0.5657448172569275  validAcc state:  1.0  \n",
            "epoch: 18 |||   vloss type:   0.911477267742157  validAcc type:   1.0 |||  vloss state 0.5697824358940125  validAcc state:  1.0  \n",
            "epoch: 18 |||   vloss type:   0.9137352108955383  validAcc type:   1.0 |||  vloss state 0.5622045993804932  validAcc state:  1.0  \n",
            "epoch: 18 |||   vloss type:   0.9135079383850098  validAcc type:   1.0 |||  vloss state 0.5644803643226624  validAcc state:  1.0  \n",
            "Time:     3034.2495226860046\n",
            "epoch: 19 0 |||   loss type:   0.913309633731842  trainAcc type:   1.0 |||  loss state 0.5586475729942322  trainAcc state:  1.0  \n",
            "epoch: 19 5 |||   loss type:   0.9198094010353088  trainAcc type:   0.984375 |||  loss state 0.5630996227264404  trainAcc state:  0.984375  \n",
            "epoch: 19 10 |||   loss type:   0.9119531512260437  trainAcc type:   1.0 |||  loss state 0.5566450953483582  trainAcc state:  1.0  \n",
            "epoch: 19 15 |||   loss type:   0.9109980463981628  trainAcc type:   1.0 |||  loss state 0.5900498628616333  trainAcc state:  0.96875  \n",
            "epoch: 19 20 |||   loss type:   0.913400411605835  trainAcc type:   1.0 |||  loss state 0.5555549263954163  trainAcc state:  1.0  \n",
            "epoch: 19 25 |||   loss type:   0.9109461307525635  trainAcc type:   1.0 |||  loss state 0.5782886743545532  trainAcc state:  0.96875  \n",
            "epoch: 19 30 |||   loss type:   0.9218433499336243  trainAcc type:   1.0 |||  loss state 0.5638484358787537  trainAcc state:  1.0  \n",
            "epoch: 19 35 |||   loss type:   0.909509539604187  trainAcc type:   1.0 |||  loss state 0.5563252568244934  trainAcc state:  1.0  \n",
            "epoch: 19 40 |||   loss type:   0.9217413663864136  trainAcc type:   1.0 |||  loss state 0.5602501630783081  trainAcc state:  1.0  \n",
            "epoch: 19 45 |||   loss type:   0.9081423878669739  trainAcc type:   1.0 |||  loss state 0.5554554462432861  trainAcc state:  1.0  \n",
            "epoch: 19 50 |||   loss type:   0.9173248410224915  trainAcc type:   1.0 |||  loss state 0.571382462978363  trainAcc state:  0.96875  \n",
            "epoch: 19 55 |||   loss type:   0.9174091219902039  trainAcc type:   1.0 |||  loss state 0.5605693459510803  trainAcc state:  1.0  \n",
            "epoch: 19 60 |||   loss type:   0.9104726910591125  trainAcc type:   1.0 |||  loss state 0.5773937106132507  trainAcc state:  0.984375  \n",
            "epoch: 19 65 |||   loss type:   0.9057540893554688  trainAcc type:   1.0 |||  loss state 0.5547221302986145  trainAcc state:  1.0  \n",
            "epoch: 19 70 |||   loss type:   0.912156343460083  trainAcc type:   1.0 |||  loss state 0.5558591485023499  trainAcc state:  1.0  \n",
            "epoch: 19 75 |||   loss type:   0.9186062812805176  trainAcc type:   0.984375 |||  loss state 0.5600054264068604  trainAcc state:  1.0  \n",
            "epoch: 19 80 |||   loss type:   0.9185987114906311  trainAcc type:   1.0 |||  loss state 0.5647991299629211  trainAcc state:  1.0  \n",
            "epoch: 19 85 |||   loss type:   0.9132550954818726  trainAcc type:   1.0 |||  loss state 0.5595101118087769  trainAcc state:  1.0  \n",
            "epoch: 19 90 |||   loss type:   0.9114220142364502  trainAcc type:   1.0 |||  loss state 0.570121705532074  trainAcc state:  0.984375  \n",
            "epoch: 19 95 |||   loss type:   0.9162826538085938  trainAcc type:   1.0 |||  loss state 0.5596762895584106  trainAcc state:  1.0  \n",
            "epoch: 19 100 |||   loss type:   0.91583651304245  trainAcc type:   1.0 |||  loss state 0.5596082210540771  trainAcc state:  1.0  \n",
            "epoch: 19 105 |||   loss type:   0.9126819372177124  trainAcc type:   1.0 |||  loss state 0.5714359879493713  trainAcc state:  0.984375  \n",
            "epoch: 19 110 |||   loss type:   0.9127857685089111  trainAcc type:   1.0 |||  loss state 0.5574508309364319  trainAcc state:  1.0  \n",
            "epoch: 19 115 |||   loss type:   0.9125949740409851  trainAcc type:   1.0 |||  loss state 0.5567249655723572  trainAcc state:  1.0  \n",
            "epoch: 19 120 |||   loss type:   0.923255205154419  trainAcc type:   1.0 |||  loss state 0.567570686340332  trainAcc state:  1.0  \n",
            "epoch: 19 125 |||   loss type:   0.9123414754867554  trainAcc type:   1.0 |||  loss state 0.5623078346252441  trainAcc state:  1.0  \n",
            "epoch: 19 130 |||   loss type:   0.9172317981719971  trainAcc type:   1.0 |||  loss state 0.5701718330383301  trainAcc state:  0.984375  \n",
            "epoch: 19 135 |||   loss type:   0.9207059144973755  trainAcc type:   1.0 |||  loss state 0.5597084760665894  trainAcc state:  1.0  \n",
            "epoch: 19 140 |||   loss type:   0.9124234914779663  trainAcc type:   1.0 |||  loss state 0.566938579082489  trainAcc state:  0.984375  \n",
            "epoch: 19 145 |||   loss type:   0.9135929942131042  trainAcc type:   1.0 |||  loss state 0.5674737691879272  trainAcc state:  0.984375  \n",
            "epoch: 19 |||   vloss type:   0.9250090718269348  validAcc type:   0.984375 |||  vloss state 0.5870906710624695  validAcc state:  0.953125  \n",
            "epoch: 19 |||   vloss type:   0.9175178408622742  validAcc type:   1.0 |||  vloss state 0.5635098218917847  validAcc state:  1.0  \n",
            "epoch: 19 |||   vloss type:   0.929495632648468  validAcc type:   1.0 |||  vloss state 0.563442587852478  validAcc state:  1.0  \n",
            "epoch: 19 |||   vloss type:   0.9304709434509277  validAcc type:   0.984375 |||  vloss state 0.5652364492416382  validAcc state:  0.984375  \n",
            "epoch: 19 |||   vloss type:   0.9232812523841858  validAcc type:   1.0 |||  vloss state 0.5673913955688477  validAcc state:  1.0  \n",
            "epoch: 19 |||   vloss type:   0.9112688302993774  validAcc type:   1.0 |||  vloss state 0.5712031722068787  validAcc state:  0.984375  \n",
            "epoch: 19 |||   vloss type:   0.9143153429031372  validAcc type:   1.0 |||  vloss state 0.5633524060249329  validAcc state:  1.0  \n",
            "epoch: 19 |||   vloss type:   0.9137755632400513  validAcc type:   1.0 |||  vloss state 0.5659182667732239  validAcc state:  1.0  \n",
            "Time:     3199.341764688492\n",
            "epoch: 20 0 |||   loss type:   0.9106966257095337  trainAcc type:   1.0 |||  loss state 0.5558626651763916  trainAcc state:  1.0  \n",
            "epoch: 20 5 |||   loss type:   0.9136455059051514  trainAcc type:   1.0 |||  loss state 0.5657842755317688  trainAcc state:  0.984375  \n",
            "epoch: 20 10 |||   loss type:   0.913497805595398  trainAcc type:   1.0 |||  loss state 0.5692248344421387  trainAcc state:  1.0  \n",
            "epoch: 20 15 |||   loss type:   0.9180891513824463  trainAcc type:   1.0 |||  loss state 0.5559483766555786  trainAcc state:  1.0  \n",
            "epoch: 20 20 |||   loss type:   0.9119386076927185  trainAcc type:   1.0 |||  loss state 0.5553002953529358  trainAcc state:  1.0  \n",
            "epoch: 20 25 |||   loss type:   0.9109626412391663  trainAcc type:   1.0 |||  loss state 0.5605936050415039  trainAcc state:  1.0  \n",
            "epoch: 20 30 |||   loss type:   0.9178341627120972  trainAcc type:   1.0 |||  loss state 0.5699787735939026  trainAcc state:  0.984375  \n",
            "epoch: 20 35 |||   loss type:   0.91344153881073  trainAcc type:   1.0 |||  loss state 0.5550095438957214  trainAcc state:  1.0  \n",
            "epoch: 20 40 |||   loss type:   0.9146929383277893  trainAcc type:   1.0 |||  loss state 0.5628017783164978  trainAcc state:  1.0  \n",
            "epoch: 20 45 |||   loss type:   0.9113043546676636  trainAcc type:   1.0 |||  loss state 0.5593603253364563  trainAcc state:  1.0  \n",
            "epoch: 20 50 |||   loss type:   0.9074065089225769  trainAcc type:   1.0 |||  loss state 0.5740780830383301  trainAcc state:  0.984375  \n",
            "epoch: 20 55 |||   loss type:   0.9111495018005371  trainAcc type:   1.0 |||  loss state 0.5576971173286438  trainAcc state:  1.0  \n",
            "epoch: 20 60 |||   loss type:   0.9132767915725708  trainAcc type:   1.0 |||  loss state 0.556423544883728  trainAcc state:  1.0  \n",
            "epoch: 20 65 |||   loss type:   0.9154625535011292  trainAcc type:   1.0 |||  loss state 0.5599888563156128  trainAcc state:  1.0  \n",
            "epoch: 20 70 |||   loss type:   0.9225757122039795  trainAcc type:   1.0 |||  loss state 0.5640349388122559  trainAcc state:  1.0  \n",
            "epoch: 20 75 |||   loss type:   0.9145253896713257  trainAcc type:   1.0 |||  loss state 0.6013182997703552  trainAcc state:  0.96875  \n",
            "epoch: 20 80 |||   loss type:   0.9120688438415527  trainAcc type:   1.0 |||  loss state 0.5613288283348083  trainAcc state:  1.0  \n",
            "epoch: 20 85 |||   loss type:   0.9119496941566467  trainAcc type:   1.0 |||  loss state 0.5610948204994202  trainAcc state:  0.984375  \n",
            "epoch: 20 90 |||   loss type:   0.9109655618667603  trainAcc type:   1.0 |||  loss state 0.5545953512191772  trainAcc state:  1.0  \n",
            "epoch: 20 95 |||   loss type:   0.9106245636940002  trainAcc type:   1.0 |||  loss state 0.5544042587280273  trainAcc state:  1.0  \n",
            "epoch: 20 100 |||   loss type:   0.9159653186798096  trainAcc type:   1.0 |||  loss state 0.5596301555633545  trainAcc state:  1.0  \n",
            "epoch: 20 105 |||   loss type:   0.9125601053237915  trainAcc type:   1.0 |||  loss state 0.5652897953987122  trainAcc state:  1.0  \n",
            "epoch: 20 110 |||   loss type:   0.9142798185348511  trainAcc type:   1.0 |||  loss state 0.5556367039680481  trainAcc state:  1.0  \n",
            "epoch: 20 115 |||   loss type:   0.9111253619194031  trainAcc type:   1.0 |||  loss state 0.5597960948944092  trainAcc state:  1.0  \n",
            "epoch: 20 120 |||   loss type:   0.912514328956604  trainAcc type:   1.0 |||  loss state 0.5691152811050415  trainAcc state:  0.984375  \n",
            "epoch: 20 125 |||   loss type:   0.9136442542076111  trainAcc type:   1.0 |||  loss state 0.5566908717155457  trainAcc state:  1.0  \n",
            "epoch: 20 130 |||   loss type:   0.9086600542068481  trainAcc type:   1.0 |||  loss state 0.5776492357254028  trainAcc state:  0.96875  \n",
            "epoch: 20 135 |||   loss type:   0.9075747728347778  trainAcc type:   1.0 |||  loss state 0.5550358295440674  trainAcc state:  1.0  \n",
            "epoch: 20 140 |||   loss type:   0.9130146503448486  trainAcc type:   1.0 |||  loss state 0.5784043073654175  trainAcc state:  0.984375  \n",
            "epoch: 20 145 |||   loss type:   0.9063290953636169  trainAcc type:   1.0 |||  loss state 0.5556095838546753  trainAcc state:  1.0  \n",
            "epoch: 20 |||   vloss type:   0.9241988658905029  validAcc type:   0.984375 |||  vloss state 0.5911210179328918  validAcc state:  0.953125  \n",
            "epoch: 20 |||   vloss type:   0.9165884852409363  validAcc type:   1.0 |||  vloss state 0.5616912245750427  validAcc state:  1.0  \n",
            "epoch: 20 |||   vloss type:   0.928239107131958  validAcc type:   1.0 |||  vloss state 0.5615845918655396  validAcc state:  1.0  \n",
            "epoch: 20 |||   vloss type:   0.9303452372550964  validAcc type:   0.984375 |||  vloss state 0.5676262378692627  validAcc state:  0.984375  \n",
            "epoch: 20 |||   vloss type:   0.9217008352279663  validAcc type:   1.0 |||  vloss state 0.5655761957168579  validAcc state:  1.0  \n",
            "epoch: 20 |||   vloss type:   0.9105347990989685  validAcc type:   1.0 |||  vloss state 0.5679046511650085  validAcc state:  1.0  \n",
            "epoch: 20 |||   vloss type:   0.9123811721801758  validAcc type:   1.0 |||  vloss state 0.5612894296646118  validAcc state:  1.0  \n",
            "epoch: 20 |||   vloss type:   0.912708044052124  validAcc type:   1.0 |||  vloss state 0.564217746257782  validAcc state:  1.0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A_h1UukyrzC",
        "outputId": "f6bc341e-676b-4607-c119-2312cc2ee379"
      },
      "source": [
        "print(\"Max train Acc: \", max(train_acc_list))\n",
        "print(\"Max valid Acc: \", max(valid_acc_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max train Acc:  0.9978645833333334\n",
            "Max valid Acc:  0.9784128289473685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDXOWfWy91D8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0dcf500-41c7-49fc-8d52-f7a7ca5097f1"
      },
      "source": [
        "if plot == True:\n",
        "        epoch_num = range(20)\n",
        "        #Plot overall loss vs epoch\n",
        "        plt.plot(epoch_num, train_loss_list, label='Train')\n",
        "        plt.plot(epoch_num, valid_loss_list, label='Valid')\n",
        "        plt.title('Overall Loss vs. Epoch')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.show()\n",
        "        plt.savefig('overall_loss')\n",
        "\n",
        "        #Plot overall Accuracy vs epoch\n",
        "        plt.plot(epoch_num, train_acc_list, label='Train')\n",
        "        plt.plot(epoch_num, valid_acc_list, label='Valid')\n",
        "        plt.title('Training Accuracy vs. Epoch')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        plt.savefig('train_acc')\n",
        "\n",
        "                #Plot TYPE loss vs epoch\n",
        "        plt.plot(epoch_num, train_loss_list_type, label='Train')\n",
        "        plt.plot(epoch_num, valid_loss_list_type, label='Valid')\n",
        "        plt.title('Type Loss vs. Epoch')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.show()\n",
        "        plt.savefig('type_loss')\n",
        "\n",
        "                #Plot TYPE Accuracy vs epoch\n",
        "        plt.plot(epoch_num, train_acc_list_type, label='Train')\n",
        "        plt.plot(epoch_num, valid_acc_list_type, label='Valid')\n",
        "        plt.title('Type Accuracy vs. Epoch')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        plt.savefig('type_acc')\n",
        "\n",
        "                #Plot STATE loss vs epoch\n",
        "        plt.plot(epoch_num, train_loss_list_state, label='Train')\n",
        "        plt.plot(epoch_num, valid_loss_list_state, label='Valid')\n",
        "        plt.title('State Loss vs. Epoch')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.show()\n",
        "        plt.savefig('state_loss')\n",
        "\n",
        "                #Plot STATE Accuracy vs epoch\n",
        "        plt.plot(epoch_num, train_acc_list_state, label='Train')\n",
        "        plt.plot(epoch_num, valid_acc_list_state, label='Valid')\n",
        "        plt.title('State Accuracy vs. Epoch')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "        plt.savefig('state_acc')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJttcDXs5Egj",
        "outputId": "1ad03efa-e7ef-4904-c71a-af6c6e9e0307"
      },
      "source": [
        "running_loss = []\n",
        "running_accuracy = []\n",
        "running_loss_state = []\n",
        "running_accuracy_state = []\n",
        "running_loss_type = []\n",
        "running_accuracy_type = []\n",
        "for i, data in enumerate(test_white_loader):\n",
        "        #get batch of data\n",
        "    inputs, label = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    label_state = torch.zeros(len(label)).to(device)\n",
        "    label_type = torch.zeros(len(label)).to(device)\n",
        "    for k in range(len(label)):\n",
        "        label_state[k] = relabel_state(label[k])\n",
        "        label_type[k] = relabel_type(label[k]) \n",
        "\n",
        "    #run model on validation batch\n",
        "    predictions_state, predictions_type = model(inputs)\n",
        "\n",
        "        #compute loss\n",
        "    batch_loss_state = loss_fnc(input=predictions_state.squeeze(), target=label_state.long())\n",
        "    batch_loss_type = loss_fnc(input=predictions_type.squeeze(), target=label_type.long())\n",
        "\n",
        "    Overall_loss = batch_loss_state + batch_loss_type\n",
        "        #evaluate\n",
        "    _, predicted_state = torch.max(predictions_state.data, 1)\n",
        "    _,predicted_type = torch.max(predictions_type.data, 1)\n",
        "\n",
        "    Acc_state = (label_state == predicted_state).sum().item() / 8\n",
        "    Acc_type = (label_type == predicted_type).sum().item() / 8\n",
        "    running_loss.append(Overall_loss.item())\n",
        "    running_accuracy.append((Acc_state+Acc_type)/2)\n",
        "\n",
        "    running_loss_state.append(batch_loss_state.item())\n",
        "    running_accuracy_state.append(Acc_state)\n",
        "    running_loss_type.append(batch_loss_type.item())\n",
        "    running_accuracy_type.append(Acc_type) \n",
        "    \n",
        "#Overall accuracy\n",
        "whiteacc_ = sum(running_accuracy) / float(len(running_accuracy))\n",
        "#state accuracy\n",
        "whiteacc_state_ = sum(running_accuracy_state) / float(len(running_accuracy_state))\n",
        "\n",
        "#type accuracy\n",
        "whiteAcc_type_ = sum(running_accuracy_type) / float(len(running_accuracy_type))\n",
        "\n",
        "#             lists for VALIDATION losses\n",
        "#Overall Loss\n",
        "white_loss_ = sum(running_loss) / float(len(running_loss))\n",
        "\n",
        "#State Loss\n",
        "white_loss_state_ = sum(running_loss_state) / float(len(running_loss_state))\n",
        "\n",
        "#Type Loss\n",
        "white_loss_type_ = sum(running_loss_type) / float(len(running_loss_type))\n",
        "\n",
        "print(\"White background accuracy:\")\n",
        "print(whiteacc_)\n",
        "print(\"White background loss:\")\n",
        "print(white_loss_)\n",
        "\n",
        "\n",
        "\n",
        "running_loss = []\n",
        "running_accuracy = []\n",
        "running_loss_state = []\n",
        "running_accuracy_state = []\n",
        "running_loss_type = []\n",
        "running_accuracy_type = []\n",
        "for i, data in enumerate(test_varied_loader):\n",
        "        #get batch of data\n",
        "    inputs, label = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    label_state = torch.zeros(len(label)).to(device)\n",
        "    label_type = torch.zeros(len(label)).to(device)\n",
        "    for k in range(len(label)):\n",
        "        label_state[k] = relabel_state(label[k])\n",
        "        label_type[k] = relabel_type(label[k]) \n",
        "\n",
        "    #run model on validation batch\n",
        "    predictions_state, predictions_type = model(inputs)\n",
        "\n",
        "        #compute loss\n",
        "    batch_loss_state = loss_fnc(input=predictions_state.squeeze(), target=label_state.long())\n",
        "    batch_loss_type = loss_fnc(input=predictions_type.squeeze(), target=label_type.long())\n",
        "\n",
        "    Overall_loss = batch_loss_state + batch_loss_type\n",
        "        #evaluate\n",
        "    _, predicted_state = torch.max(predictions_state.data, 1)\n",
        "    _,predicted_type = torch.max(predictions_type.data, 1)\n",
        "\n",
        "    Acc_state = (label_state == predicted_state).sum().item() / 8\n",
        "    Acc_type = (label_type == predicted_type).sum().item() / 8\n",
        "    running_loss.append(Overall_loss.item())\n",
        "    running_accuracy.append((Acc_state+Acc_type)/2)\n",
        "\n",
        "    running_loss_state.append(batch_loss_state.item())\n",
        "    running_accuracy_state.append(Acc_state)\n",
        "    running_loss_type.append(batch_loss_type.item())\n",
        "    running_accuracy_type.append(Acc_type) \n",
        "    \n",
        "#Overall accuracy\n",
        "variedacc_ = sum(running_accuracy) / float(len(running_accuracy))\n",
        "#state accuracy\n",
        "variedacc_state_ = sum(running_accuracy_state) / float(len(running_accuracy_state))\n",
        "\n",
        "#type accuracy\n",
        "variedAcc_type_ = sum(running_accuracy_type) / float(len(running_accuracy_type))\n",
        "\n",
        "#             lists for VALIDATION losses\n",
        "#Overall Loss\n",
        "varied_loss_ = sum(running_loss) / float(len(running_loss))\n",
        "\n",
        "#State Loss\n",
        "varied_loss_state_ = sum(running_loss_state) / float(len(running_loss_state))\n",
        "\n",
        "#Type Loss\n",
        "varied_loss_type_ = sum(running_loss_type) / float(len(running_loss_type))\n",
        "\n",
        "print(\"Varied background accuracy:\")\n",
        "print(variedacc_)\n",
        "print(\"Varied background loss:\")\n",
        "print(varied_loss_)\n",
        "\n",
        "\n",
        "\n",
        "running_loss = []\n",
        "running_accuracy = []\n",
        "running_loss_state = []\n",
        "running_accuracy_state = []\n",
        "running_loss_type = []\n",
        "running_accuracy_type = []\n",
        "for i, data in enumerate(test_loader):\n",
        "        #get batch of data\n",
        "    inputs, label = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    label_state = torch.zeros(len(label)).to(device)\n",
        "    label_type = torch.zeros(len(label)).to(device)\n",
        "    for k in range(len(label)):\n",
        "        label_state[k] = relabel_state(label[k])\n",
        "        label_type[k] = relabel_type(label[k]) \n",
        "\n",
        "    #run model on validation batch\n",
        "    predictions_state, predictions_type = model(inputs)\n",
        "\n",
        "        #compute loss\n",
        "    batch_loss_state = loss_fnc(input=predictions_state.squeeze(), target=label_state.long())\n",
        "    batch_loss_type = loss_fnc(input=predictions_type.squeeze(), target=label_type.long())\n",
        "\n",
        "    Overall_loss = batch_loss_state + batch_loss_type\n",
        "        #evaluate\n",
        "    _, predicted_state = torch.max(predictions_state.data, 1)\n",
        "    _,predicted_type = torch.max(predictions_type.data, 1)\n",
        "\n",
        "    Acc_state = (label_state == predicted_state).sum().item() / 64\n",
        "    Acc_type = (label_type == predicted_type).sum().item() / 64\n",
        "    running_loss.append(Overall_loss.item())\n",
        "    running_accuracy.append((Acc_state+Acc_type)/2)\n",
        "\n",
        "    running_loss_state.append(batch_loss_state.item())\n",
        "    running_accuracy_state.append(Acc_state)\n",
        "    running_loss_type.append(batch_loss_type.item())\n",
        "    running_accuracy_type.append(Acc_type) \n",
        "    \n",
        "#Overall accuracy\n",
        "testacc_ = sum(running_accuracy) / float(len(running_accuracy))\n",
        "#state accuracy\n",
        "testacc_state_ = sum(running_accuracy_state) / float(len(running_accuracy_state))\n",
        "\n",
        "#type accuracy\n",
        "testAcc_type_ = sum(running_accuracy_type) / float(len(running_accuracy_type))\n",
        "\n",
        "#             lists for VALIDATION losses\n",
        "#Overall Loss\n",
        "test_loss_ = sum(running_loss) / float(len(running_loss))\n",
        "\n",
        "#State Loss\n",
        "test_loss_state_ = sum(running_loss_state) / float(len(running_loss_state))\n",
        "\n",
        "#Type Loss\n",
        "test_loss_type_ = sum(running_loss_type) / float(len(running_loss_type))\n",
        "\n",
        "print(\"Test set accuracy:\")\n",
        "print(testacc_)\n",
        "print(\"Test set loss:\")\n",
        "print(test_loss_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "White background accuracy:\n",
            "0.93125\n",
            "White background loss:\n",
            "1.4906188011169434\n",
            "Varied background accuracy:\n",
            "0.925\n",
            "Varied background loss:\n",
            "1.5041053771972657\n",
            "Test set accuracy:\n",
            "0.9853723404255319\n",
            "Test set loss:\n",
            "1.4942273763900107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uBSKd-GwCtc"
      },
      "source": [
        "def recombine_prediction(argument1,argument2):\n",
        "    switcher = {\n",
        "         str([0,0]): 0,\n",
        "         str([0,1]): 1,\n",
        "         str([0,2]): 2,\n",
        "         str([0,3]): 3,\n",
        "         str([0,4]): 4,\n",
        "         str([1,0]): 5,\n",
        "         str([1,1]): 6,\n",
        "         str([1,2]): 7,\n",
        "         str([1,3]): 8,\n",
        "         str([1,4]): 9,\n",
        "         str([2,0]):10,\n",
        "         str([2,1]):11,\n",
        "         str([2,2]):12,\n",
        "         str([2,3]):13,\n",
        "         str([2,4]):14}\n",
        "    return switcher[str([argument1.item(),argument2.item()])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmTQJBHnu_mn",
        "outputId": "4533f614-fcf1-4d73-e050-2b87ba5bb0d5"
      },
      "source": [
        " from sklearn.metrics import confusion_matrix\n",
        "# Initialize the prediction and label lists(tensors)\n",
        "predlist_state=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "lbllist_state=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "predlist_type=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "lbllist_type=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "predlist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "lbllist=torch.zeros(0,dtype=torch.long, device='cpu')\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, data in enumerate(valid_loader):\n",
        "        inputs, label = data[0].to(device), data[1].to(device)\n",
        "        vlabel_state = torch.zeros(len(label)).to(device)\n",
        "        vlabel_type = torch.zeros(len(label)).to(device)\n",
        "        for k in range(len(label)):\n",
        "            vlabel_state[k] = relabel_state(label[k])\n",
        "            vlabel_type[k] = relabel_type(label[k])\n",
        "            \n",
        "        \n",
        "        predictions_state_v, predictions_type_v = model(inputs)\n",
        "        _, predicted_state_v = torch.max(predictions_state_v.data, 1)\n",
        "        _,predicted_type_v = torch.max(predictions_type_v.data, 1)\n",
        "\n",
        "        # Append batch prediction results\n",
        "        predlist_state=torch.cat([predlist_state,predicted_state_v.view(-1).cpu()])\n",
        "        lbllist_state=torch.cat([lbllist_state,vlabel_state.view(-1).cpu()])\n",
        "        predlist_type=torch.cat([predlist_type,predicted_type_v.view(-1).cpu()])\n",
        "        lbllist_type=torch.cat([lbllist_type,vlabel_type.view(-1).cpu()])\n",
        "        \n",
        "        predicted = torch.zeros(len(label)).to(device)\n",
        "        # 15 label confusion matrix\n",
        "        for k in range(len(predicted_state_v)):\n",
        "            predicted[k] = recombine_prediction(predicted_state_v[k],predicted_type_v[k])\n",
        "        predlist=torch.cat([predlist,predicted.view(-1).cpu()])\n",
        "        lbllist=torch.cat([lbllist,label.view(-1).cpu()])\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Confusion matrix\n",
        "conf_mat_state=confusion_matrix(lbllist_state.numpy(), predlist_state.numpy())\n",
        "conf_mat_type=confusion_matrix(lbllist_type.numpy(), predlist_type.numpy())\n",
        "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_mat)\n",
        "print(\"State Confusion Matrix\")\n",
        "print(conf_mat_state)\n",
        "print(\"Type Confusion Matrix\")\n",
        "print(conf_mat_type)\n",
        "\n",
        "# Per-class accuracy\n",
        "class_accuracy=100*conf_mat.diagonal()/conf_mat.sum(1)\n",
        "print(\"Class Accuracy\")\n",
        "print(class_accuracy)\n",
        "class_accuracy_state=100*conf_mat_state.diagonal()/conf_mat_state.sum(1)\n",
        "print(\"State Accuracy\")\n",
        "print(class_accuracy_state)\n",
        "class_accuracy_type=100*conf_mat_type.diagonal()/conf_mat_type.sum(1)\n",
        "print(\"Type Accuracy\")\n",
        "print(class_accuracy_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[144   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 154   0   0   0   0   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0 150   0   0   0   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0 180   0   0   0   0   5   0   0   0   0   0   0]\n",
            " [  0   0   0   0 149   0   0   0   0   2   0   0   0   0   0]\n",
            " [  3   0   0   0   0 158   0   3   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   4   0   0   0   0 147   0   0   0   0   0   0   0]\n",
            " [  0   0   0   6   0   0   0   0 165   0   0   0   0   0   0]\n",
            " [  0   0   0   0   4   0   0   0   4 143   0   0   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0 160   0   4   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 156   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   1   0 166   0   0]\n",
            " [  0   0   0   2   0   0   0   0   0   0   0   0   0 144   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 160]]\n",
            "State Confusion Matrix\n",
            "[[777   9   0]\n",
            " [ 18 802   1]\n",
            " [  2   0 791]]\n",
            "Type Confusion Matrix\n",
            "[[465   0   7   0   0]\n",
            " [  0 494   0   0   0]\n",
            " [  1   0 468   0   0]\n",
            " [  0   0   0 502   0]\n",
            " [  0   0   0   4 459]]\n",
            "Class Accuracy\n",
            "[100.          99.35483871  99.33774834  97.2972973   98.67549669\n",
            "  96.34146341  99.45355191  97.35099338  96.49122807  94.07894737\n",
            "  97.56097561 100.          99.4011976   98.63013699 100.        ]\n",
            "State Accuracy\n",
            "[98.85496183 97.68574909 99.74779319]\n",
            "Type Accuracy\n",
            "[ 98.51694915 100.          99.78678038 100.          99.13606911]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYA_lbuM1_JM",
        "outputId": "59d5a9aa-914e-4d2b-9a51-14f85d7bd3c4"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "# Confusion matrix and classification report\n",
        "conf_mat_state=confusion_matrix(lbllist_state.numpy(), predlist_state.numpy())\n",
        "conf_mat_type=confusion_matrix(lbllist_type.numpy(), predlist_type.numpy())\n",
        "conf_mat=confusion_matrix(lbllist.numpy(), predlist.numpy())\n",
        "class_report_state = classification_report(lbllist_state.numpy(), predlist_state.numpy())\n",
        "class_report_type = classification_report(lbllist_type.numpy(), predlist_type.numpy())\n",
        "class_report = classification_report(lbllist.numpy(), predlist.numpy())\n",
        "print(conf_mat)\n",
        "print(conf_mat_state)\n",
        "print(conf_mat_type)\n",
        "print(\"State class report:\")\n",
        "print(class_report_state)\n",
        "print(\"Type class report:\")\n",
        "print(class_report_type)\n",
        "print(\"Class report\")\n",
        "print(class_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[144   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0 154   0   0   0   0   1   0   0   0   0   0   0   0   0]\n",
            " [  0   0 150   0   0   0   0   1   0   0   0   0   0   0   0]\n",
            " [  0   0   0 180   0   0   0   0   5   0   0   0   0   0   0]\n",
            " [  0   0   0   0 149   0   0   0   0   2   0   0   0   0   0]\n",
            " [  3   0   0   0   0 158   0   3   0   0   0   0   0   0   0]\n",
            " [  0   1   0   0   0   0 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   4   0   0   0   0 147   0   0   0   0   0   0   0]\n",
            " [  0   0   0   6   0   0   0   0 165   0   0   0   0   0   0]\n",
            " [  0   0   0   0   4   0   0   0   4 143   0   0   0   0   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0 160   0   4   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 156   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   1   0 166   0   0]\n",
            " [  0   0   0   2   0   0   0   0   0   0   0   0   0 144   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 160]]\n",
            "[[777   9   0]\n",
            " [ 18 802   1]\n",
            " [  2   0 791]]\n",
            "[[465   0   7   0   0]\n",
            " [  0 494   0   0   0]\n",
            " [  1   0 468   0   0]\n",
            " [  0   0   0 502   0]\n",
            " [  0   0   0   4 459]]\n",
            "State class report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.99      0.98       786\n",
            "         1.0       0.99      0.98      0.98       821\n",
            "         2.0       1.00      1.00      1.00       793\n",
            "\n",
            "    accuracy                           0.99      2400\n",
            "   macro avg       0.99      0.99      0.99      2400\n",
            "weighted avg       0.99      0.99      0.99      2400\n",
            "\n",
            "Type class report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.99      0.99       472\n",
            "         1.0       1.00      1.00      1.00       494\n",
            "         2.0       0.99      1.00      0.99       469\n",
            "         3.0       0.99      1.00      1.00       502\n",
            "         4.0       1.00      0.99      1.00       463\n",
            "\n",
            "    accuracy                           0.99      2400\n",
            "   macro avg       1.00      0.99      0.99      2400\n",
            "weighted avg       1.00      0.99      0.99      2400\n",
            "\n",
            "Class report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       144\n",
            "           1       0.99      0.99      0.99       155\n",
            "           2       0.97      0.99      0.98       151\n",
            "           3       0.96      0.97      0.97       185\n",
            "           4       0.97      0.99      0.98       151\n",
            "           5       1.00      0.96      0.98       164\n",
            "           6       0.99      0.99      0.99       183\n",
            "           7       0.97      0.97      0.97       151\n",
            "           8       0.95      0.96      0.96       171\n",
            "           9       0.99      0.94      0.96       152\n",
            "          10       0.99      0.98      0.98       164\n",
            "          11       1.00      1.00      1.00       156\n",
            "          12       0.98      0.99      0.99       167\n",
            "          13       1.00      0.99      0.99       146\n",
            "          14       0.99      1.00      1.00       160\n",
            "\n",
            "    accuracy                           0.98      2400\n",
            "   macro avg       0.98      0.98      0.98      2400\n",
            "weighted avg       0.98      0.98      0.98      2400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMDHvBPEK5g5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d54d5a-e42c-4e29-a309-1687c0218137"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model,(3,224,224))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
            "              ReLU-3         [-1, 64, 224, 224]               0\n",
            "            Conv2d-4         [-1, 64, 224, 224]          36,928\n",
            "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
            "              ReLU-6         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-7         [-1, 64, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
            "       BatchNorm2d-9        [-1, 128, 112, 112]             256\n",
            "             ReLU-10        [-1, 128, 112, 112]               0\n",
            "           Conv2d-11        [-1, 128, 112, 112]         147,584\n",
            "      BatchNorm2d-12        [-1, 128, 112, 112]             256\n",
            "             ReLU-13        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-14          [-1, 128, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         295,168\n",
            "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
            "             ReLU-17          [-1, 256, 56, 56]               0\n",
            "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
            "             ReLU-20          [-1, 256, 56, 56]               0\n",
            "           Conv2d-21          [-1, 256, 56, 56]         590,080\n",
            "      BatchNorm2d-22          [-1, 256, 56, 56]             512\n",
            "             ReLU-23          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-24          [-1, 256, 28, 28]               0\n",
            "           Conv2d-25          [-1, 512, 28, 28]       1,180,160\n",
            "      BatchNorm2d-26          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-27          [-1, 512, 28, 28]               0\n",
            "           Conv2d-28          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-29          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-30          [-1, 512, 28, 28]               0\n",
            "           Conv2d-31          [-1, 512, 28, 28]       2,359,808\n",
            "      BatchNorm2d-32          [-1, 512, 28, 28]           1,024\n",
            "             ReLU-33          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-34          [-1, 512, 14, 14]               0\n",
            "           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-36          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-37          [-1, 512, 14, 14]               0\n",
            "           Conv2d-38          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-39          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-40          [-1, 512, 14, 14]               0\n",
            "           Conv2d-41          [-1, 512, 14, 14]       2,359,808\n",
            "      BatchNorm2d-42          [-1, 512, 14, 14]           1,024\n",
            "             ReLU-43          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-44            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-45            [-1, 512, 7, 7]               0\n",
            "           Linear-46                 [-1, 4096]     102,764,544\n",
            "             ReLU-47                 [-1, 4096]               0\n",
            "           Linear-48                    [-1, 3]          12,291\n",
            "          Sigmoid-49                    [-1, 3]               0\n",
            "           Linear-50                 [-1, 4096]     102,764,544\n",
            "             ReLU-51                 [-1, 4096]               0\n",
            "           Linear-52                    [-1, 5]          20,485\n",
            "          Sigmoid-53                    [-1, 5]               0\n",
            "================================================================\n",
            "Total params: 220,285,000\n",
            "Trainable params: 205,561,864\n",
            "Non-trainable params: 14,723,136\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 322.07\n",
            "Params size (MB): 840.32\n",
            "Estimated Total Size (MB): 1162.97\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}