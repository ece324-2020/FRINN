{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transfer Learning One Model.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPR0xeuVFDXLaqElSB6R7he"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"TkO_CXVxAjBp"},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","import torchvision.transforms as transforms\n","from torch.utils.data import SubsetRandomSampler\n","import torch.utils.data as data\n","from torchsummary import summary\n","import torch.nn.functional as F\n","from time import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vf2Tx9QEApDA"},"source":["vgg = models.vgg16_bn(pretrained=True)\n","for param in vgg.features.parameters():\n","    param.requires_grad = False\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sBy-fQqIAqws"},"source":["#add convolutional layer\n","# custom_layers = nn.Sequential(\n","#                 nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","#                 nn.ReLU(inplace=True),\n","#                 nn.MaxPool2d(2,2),\n","#                 nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","#                 nn.ReLU(inplace=True)\n","#                 )\n","\n","#Convolutional Layer with Batch Norm\n","vgg.features[43] = nn.Sequential(vgg.features[43],nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n","                nn.ReLU(inplace=True),nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n","\n","#\n","#Two Convolutional Layer with Batch Norm\n","# vgg.features[43] = nn.Sequential(vgg.features[43],nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n","#                 nn.ReLU(inplace=True),nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),nn.Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n","#                 nn.ReLU(inplace=True),nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False))\n","\n","print(nn.Sequential(*list(vgg.children())[:-1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYOU58jbAzka"},"source":["my_transform = transforms.Compose([\n","  transforms.ToTensor(),\n","  transforms.ToPILImage(),\n","  transforms.Resize((224,224)),\n","  transforms.ToTensor(),\n","  transforms.Normalize(mean = [0.66445047,0.55465436,0.447036], std = [0.321551,0.33547384,0.3524585])\n","  ])\n","dataset =  torchvision.datasets.ImageFolder(r\"C:\\Users\\Mark\\Desktop\\3rd year 1st term\\ECE324\\Project\\Clean Data\\Clean Data\", transform=my_transform)\n","\n","train_data, valid_data, test_data = torch.utils.data.random_split(dataset, [9600,2400,3000], generator=torch.Generator().manual_seed(0))\n","\n","train_loader = data.DataLoader(train_data, batch_size=64,shuffle= True)\n","valid_loader = data.DataLoader(valid_data, batch_size=64,shuffle= False)\n","test_loader = data.DataLoader(test_data, batch_size=64,shuffle= False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YsViICbRA4z1"},"source":["\n","def relabel_state(argument):\n","    switcher = {\n","        0: 0,\n","        1: 0,\n","        2: 0,\n","        3: 0,\n","        4: 0,\n","        5: 1,\n","        6: 1,\n","        7: 1,\n","        8: 1,\n","        9: 1,\n","        10:2,\n","        11:2,\n","        12:2,\n","        13:2,\n","        14:2}\n","    return switcher[argument.item()]\n","\n","def relabel_type(argument):\n","    switcher = {\n","        0: 0,\n","        1: 1,\n","        2: 2,\n","        3: 3,\n","        4: 4,\n","        5: 0,\n","        6: 1,\n","        7: 2,\n","        8: 3,\n","        9: 4,\n","        10:0,\n","        11:1,\n","        12:2,\n","        13:3,\n","        14:4}\n","    return switcher[argument.item()]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wuOjD66RBBuh"},"source":["class MyVgg(nn.Module):\n","    def __init__(self,originalmodel):\n","        super(MyVgg,self).__init__()\n","        vgg = originalmodel\n","        # Here you get the bottleneck/feature extractor\n","        self.vgg_feature_extractor = nn.Sequential(*list(vgg.children())[:-1])\n","        self.classifier1 = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 2048),\n","            nn.ReLU(True),\n","            nn.Linear(2048, 2048),\n","            nn.ReLU(True),\n","            nn.Linear(2048, 3),\n","            nn.Sigmoid()\n","        )\n","\n","    # Set your own forward pass\n","    def forward(self, img, extra_info=None):\n","\n","        x = self.vgg_feature_extractor(img)\n","        x = x.view(x.size(0), -1)\n","        x1 = self.classifier1(x)\n","\n","        return x1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"44oEenjlBnNI"},"source":["\n","#MODEL ARGUMENTS\n","lr = 0.1\n","epochs = 10\n","eval_every = 60\n","model = MyVgg(vgg)\n","model = model.to(device)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","loss_fnc= torch.nn.CrossEntropyLoss()\n","loss_fnc =loss_fnc.to(device)\n","\n","\n","\n","#OUTPUT DATA ARGUMENTS\n","seed = 1\n","torch.manual_seed(seed)\n","save= True\n","confusion=True\n","plot = True\n","statistics = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NWR1vWCgBpqt"},"source":["\n","train_loss_list = []\n","train_acc_list = []\n","train_loss_list_state = []\n","train_acc_list_state = []\n","\n","valid_loss_list = []\n","valid_acc_list = []\n","valid_loss_list_state = []\n","valid_acc_list_state = []\n","\n","epoch_num = []         #Epoch number\n","start = time()\n","for e in range(epochs):\n","    print(\"Time:    \", time() - start)\n","    running_loss = []\n","    running_accuracy = []\n","    running_loss_state = []\n","    running_accuracy_state = []\n","\n","    running_valid_loss = []\n","    running_valid_accuracy = []\n","    running_valid_loss_state = []\n","    running_valid_accuracy_state = []\n","    model.train()\n","  #               LOOKING AT TRAINING DATA\n","\n","    for i, data in enumerate(train_loader):\n","\n","            #get batch of data\n","        inputs, label = data[0].to(device), data[1].to(device)\n","\n","        label_state = torch.zeros(len(label)).to(device)\n","        for k in range(len(label)):\n","          label_state[k] = relabel_state(label[k])\n","\n","        # Setting gradients to zero and running model on batch\n","        optimizer.zero_grad()\n","        predictions_state = model(inputs)\n","\n","        # Computing loss based on Cross Entropy\n","        batch_loss_state = loss_fnc(input=predictions_state.squeeze(), target=label_state.long())\n","\n","        # Combining losses and calculating gradients\n","        Overall_loss = batch_loss_state\n","        Overall_loss.backward()\n","        optimizer.step()\n","\n","        # Evaluating Training Acc\n","        _, predicted_state = torch.max(predictions_state.data, 1)\n","        trainAcc_state = (label_state == predicted_state).sum().item() /64\n","\n","\n","        if i % eval_every == 0:\n","           print(\"epoch: {} {}    ||| train loss state {}  trainAcc state:  {}  \".format(e+1,i, batch_loss_state, trainAcc_state))\n","\n","        running_loss.append(Overall_loss.item())\n","        running_accuracy.append(trainAcc_state)\n","        running_loss_state.append(batch_loss_state.item())\n","        running_accuracy_state.append(trainAcc_state)\n","\n","        del Overall_loss\n","        del batch_loss_state\n","        del label_state\n","        del predictions_state\n","\n","\n","\n","    #\n","    model.eval()\n","    for j, data in enumerate(valid_loader):\n","            #get batch of data\n","        inputs, label = data[0].to(device), data[1].to(device)\n","\n","        vlabel_state = torch.zeros(len(label)).to(device)\n","        for k in range(len(label)):\n","            vlabel_state[k] = relabel_state(label[k])\n","\n","        #run model on validation batch\n","        predictions_state_v= model(inputs)\n","\n","            #compute loss\n","        batch_valid_loss_state = loss_fnc(input=predictions_state_v.squeeze(), target=vlabel_state.long())\n","\n","        Overall_loss_v = batch_valid_loss_state\n","            #evaluate\n","        _, predicted_state_v = torch.max(predictions_state_v.data, 1)\n","\n","        validAcc_state = (vlabel_state == predicted_state_v).sum().item() / 64\n","\n","        if j % eval_every == 0:\n","            print(\"epoch: {} |||  vloss state {}  validAcc state:  {}  \".format(e+1, batch_valid_loss_state,validAcc_state))\n","\n","        running_valid_loss.append(Overall_loss_v.item())\n","        running_valid_accuracy.append(validAcc_state)\n","\n","        running_valid_loss_state.append(batch_valid_loss_state.item())\n","        running_valid_accuracy_state.append(validAcc_state)\n","        del Overall_loss_v\n","        del batch_valid_loss_state\n","        del vlabel_state\n","        del predicted_state_v\n","\n","    #\n","    #Overall accuracy\n","    trainacc_ = sum(running_accuracy) / float(len(running_accuracy))\n","    train_acc_list.append(trainacc_)\n","    #state accuracy\n","    trainacc_state_ = sum(running_accuracy_state) / float(len(running_accuracy_state))\n","    train_acc_list_state.append(trainacc_state_)\n","#\n","    #             lists for TRAINING losses\n","    #Overall Loss\n","    loss_ = sum(running_loss) / float(len(running_loss))\n","    train_loss_list.append(loss_)\n","    #State Loss\n","    loss_state_ = sum(running_loss_state) / float(len(running_loss_state))\n","    train_loss_list_state.append(loss_state_)\n","\n","    #------------------------------------------------------------------------------------\n","    #             lists for VALIDATION accuracy\n","    #Overall accuracy\n","    validacc_ = sum(running_valid_accuracy) / float(len(running_valid_accuracy))\n","    valid_acc_list.append(validacc_)\n","    #state accuracy\n","    validacc_state_ = sum(running_valid_accuracy_state) / float(len(running_valid_accuracy_state))\n","    valid_acc_list_state.append(validacc_state_)\n","    #             lists for VALIDATION losses\n","    #Overall Loss\n","    valid_loss_ = sum(running_valid_loss) / float(len(running_valid_loss))\n","    valid_loss_list.append(valid_loss_)\n","    #State Loss\n","    valid_loss_state_ = sum(running_valid_loss_state) / float(len(running_valid_loss_state))\n","    valid_loss_list_state.append(valid_loss_state_)\n","\n","    epoch_num.append(e)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o4isK0h6Bvvw"},"source":["# torch.save(model, r\"C:\\Users\\Mark\\Desktop\\3rd year 1st term\\ECE324\\Project\\Transfer Learning\\Model\\unfreeze2048.pt\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V5RunDngBwR2"},"source":["\n","#Plot overall loss vs epoch\n","plt.figure()\n","plt.plot(epoch_num, train_loss_list, label='Train')\n","plt.plot(epoch_num, valid_loss_list, label='Valid')\n","plt.title('Overall Loss vs. Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.show()\n","plt.savefig(r\"C:\\Users\\Mark\\Desktop\\3rd year 1st term\\ECE324\\Project\\Transfer Learning\\Plot\\Overall Loss vs. Epoch.png\")\n","\n","#Plot overall Accuracy vs epoch\n","plt.figure()\n","plt.plot(epoch_num, train_acc_list, label='Train')\n","plt.plot(epoch_num, valid_acc_list, label='Valid')\n","plt.title('Overall Accuracy vs. Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","plt.savefig(r\"C:\\Users\\Mark\\Desktop\\3rd year 1st term\\ECE324\\Project\\Transfer Learning\\Plot\\Overall Accuracy vs. Epoch.png\")\n","\n","\n","#Plot State loss vs epoch\n","plt.figure()\n","plt.plot(epoch_num, train_loss_list_state, label='Train')\n","plt.plot(epoch_num, valid_loss_list_state, label='Valid')\n","plt.title('State Loss vs. Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.show()\n","plt.savefig(r\"C:\\Users\\Mark\\Desktop\\3rd year 1st term\\ECE324\\Project\\Transfer Learning\\Plot\\State Loss vs. Epoch.png\")\n","\n","#Plot TYPE Accuracy vs epoch\n","plt.figure()\n","plt.plot(epoch_num, train_acc_list_state, label='Train')\n","plt.plot(epoch_num, valid_acc_list_state, label='Valid')\n","plt.title('State Accuracy vs. Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","plt.savefig(r\"C:\\Users\\Mark\\Desktop\\3rd year 1st term\\ECE324\\Project\\Transfer Learning\\Plot\\State Accuracy vs. Epoch.png\")\n"],"execution_count":null,"outputs":[]}]}